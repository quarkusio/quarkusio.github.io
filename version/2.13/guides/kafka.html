<!DOCTYPE html>
<html lang="en">







<head>
  <title>Apache Kafka Reference Guide - 2.13 - Quarkus</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Security-Policy" content="
  connect-src 'self' https://dpm.demdex.net https://adobedc.demdex.net https://route-default-test-mscherer-matamo.apps.ospo-osci.z3b1.p1.openshiftapps.com/ https://search.quarkus.io https://smetrics.redhat.com; 
  script-src 'self' 'unsafe-inline' 'unsafe-eval'
      
      https://assets.adobedtm.com
      js.bizographics.com
      https://www.redhat.com
      https://static.redhat.com
      https://app.requestly.io/
      jsonip.com
      https://ajax.googleapis.com
      https://use.fontawesome.com
      http://www.youtube.com
      http://www.googleadservices.com
      https://googleads.g.doubleclick.net
      https://giscus.app
      https://route-default-test-mscherer-matamo.apps.ospo-osci.z3b1.p1.openshiftapps.com/
      https://app.mailjet.com;

  style-src 'self' https://fonts.googleapis.com https://use.fontawesome.com; 
  img-src 'self' * data:; 
  media-src 'self'; 
  frame-src https://redhat.demdex.net https://www.youtube.com https://embed.restream.io https://app.mailjet.com http://xy0p2.mjt.lu https://mj.quarkus.io https://giscus.app; 
  base-uri 'none'; 
  object-src 'none'; 
  form-action 'none'; 
  font-src 'self' https://use.fontawesome.com https://fonts.gstatic.com;" />
  <script id="adobe_dtm" src="https://www.redhat.com/dtm.js" type="text/javascript"></script>
  <script src="/assets/javascript/highlight.pack.js" type="text/javascript"></script>
  <META HTTP-EQUIV='X-XSS-Protection' CONTENT="1; mode=block">
  <META HTTP-EQUIV='X-Content-Type-Options' CONTENT="nosniff">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Quarkus: Supersonic Subatomic Java">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@QuarkusIO"> 
  <meta name="twitter:creator" content="@QuarkusIO">
  <meta property="og:url" content="https://quarkus.io/version/2.13/guides/kafka" />
  <meta property="og:title" content="Apache Kafka Reference Guide - 2.13" />
  <meta property="og:description" content="Quarkus: Supersonic Subatomic Java" />
  <meta property="og:image" content="https://quarkus.io/assets/images/quarkus_card.png" />
  
  <link rel="canonical" href="https://quarkus.io/guides/kafka">
  <link rel="shortcut icon" type="image/png" href="/favicon.ico" >
  <link rel="stylesheet" href="/guides/stylesheet/config.css" />
  <link rel="stylesheet" href="/assets/css/main.css?2021-07-29" />
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.5.2/css/all.css" crossorigin="anonymous">
  <link rel="alternate" type="application/rss+xml"  href="/feed.xml" title="Quarkus">
  <script src="/assets/javascript/hl.js" type="text/javascript"></script>
  
  
  
  
  <link rel="alternate" hreflang="en" href="https://quarkus.io/version/2.13/guides/kafka" />
  
  <link rel="alternate" hreflang="pt-br" href="https://pt.quarkus.io/version/2.13/guides/kafka" />
  
  <link rel="alternate" hreflang="es" href="https://es.quarkus.io/version/2.13/guides/kafka" />
  
  <link rel="alternate" hreflang="zh" href="https://cn.quarkus.io/version/2.13/guides/kafka" />
  
  <link rel="alternate" hreflang="ja" href="https://ja.quarkus.io/version/2.13/guides/kafka" />
  
  <link rel="alternate" hreflang="x-default" href="https://quarkus.io/" />  
  <script src="/assets/javascript/tracking.js"></script>
  
  <script src="/assets/javascript/colormode.js" type="text/javascript"></script>

</head>

<body class="guides">

  
  <div class="nav-wrapper">
  <div class="grid-wrapper">
    <div class="width-12-12">
      <input type="checkbox" id="checkbox" />
      <nav id="main-nav" class="main-nav">
        <div class="logo-wrapper">
           <a href="/"><img src="/assets/images/quarkus_logo_horizontal_rgb_600px_reverse.png" class="project-logo" title="Quarkus"></a>
        </div>
    <label class="nav-toggle" for="checkbox">
      <i class="fa fa-bars"></i>
    </label>
    <ul id="menu" class="menu">
      <li class="dropdown">
        <span href="/about/">Why<i class="fas fa-chevron-down"></i></span>
        <ul class="submenu">
          <li><a href="/about" class="">WHAT IS QUARKUS?</a></li>
          <li><a href="/container-first" class="">CONTAINER FIRST</a></li>
          <li><a href="/continuum" class="">VERSATILITY</a></li>
          <li><a href="/developer-joy" class="">DEVELOPER JOY</a></li>
          <li><a href="/kubernetes-native" class="">KUBERNETES NATIVE</a></li>
          <li><a href="/standards" class="">STANDARDS</a></li>
        </ul>
      </li>
      <li class="dropdown">
        <span href="/learn/">Learn<i class="fas fa-chevron-down"></i></span>
        <ul class="submenu">
          <li><a href="/get-started" class="">GET STARTED</a></li>
          <li><a href="/guides" class="active">DOCUMENTATION</a></li>
          <li><a href="/qtips" class="">"Q" TIP VIDEOS</a></li>          
          <li><a href="/books" class="">BOOKS</a></li>
          </ul>
      </li>
      <li class="dropdown">
        <span href="https://quarkus.io/extensions/">Extensions<i class="fas fa-chevron-down"></i></span>
        <ul class="submenu">
          <!-- Note that quarkus.io is hardcoded here, because it is the only url which supports extensions -->
          <li><a href="https://quarkus.io/extensions/" class="">BROWSE EXTENSIONS</a></li>
          <li><a href="/faq/#what-is-a-quarkus-extension" class="">USE EXTENSIONS</a></li>
          <li><a href="/guides/writing-extensions" class="">CREATE EXTENSIONS</a></li>
          <li><a href="https://hub.quarkiverse.io" class="">SHARE EXTENSIONS</a></li>
        </ul>
      </li>
      <li class="dropdown">
        <span href="/community/">Community<i class="fas fa-chevron-down"></i></span>
        <ul class="submenu">
          <li><a href="/support/" class="">SUPPORT</a></li>
          <li><a href="/blog" class="">BLOG</a></li>
          <li><a href="/discussion" class="">DISCUSSION</a></li>
          <li><a href="/working-groups" class="">WORKING GROUPS</a></li>
          <li><a href="/insights" class="">PODCAST</a></li>
          <li><a href="/events" class="">EVENTS</a></li>
          <li><a href="/newsletter" class="">NEWSLETTER</a></li>
          <li><a href="https://github.com/orgs/quarkusio/projects/13/views/1" class="">ROADMAP</a></li>
          </ul>
      </li>
      <li>
        <a href="https://code.quarkus.io" class="button-cta secondary white">START CODING</a>
      </li>
      <li class="dropdown">
        <span href="/language/"><div class="fas fa-globe langicon"></div><i class="fas fa-chevron-down"></i></span>
        <ul class="submenu">
          <li><a href="https://quarkus.io/version/2.13/guides/kafka" >OFFICIAL (ENGLISH)</a></li>
          <li><a href="https://pt.quarkus.io/version/2.13/guides/kafka">PORTUGUÊS (BR)</a></li>
          <li><a href="https://es.quarkus.io/version/2.13/guides/kafka">ESPAÑOL</a></li>
          <li><a href="https://cn.quarkus.io/version/2.13/guides/kafka">简体中文</a></li>
          <li><a href="https://ja.quarkus.io/version/2.13/guides/kafka">日本語</a></li>
          </ul>
      </li>
      <li>
        <span href="#" class="modeswitcher" id='theme-toggle'><i class="fas fa-sun"></i><i class="fas fa-moon"></i><i class="fas fa-cog"></i></span>
      </li>
    </ul>
      </nav>
    </div>
  </div>
</div>

  <div class="content">
    







<section class="full-width-version-bg flexfilterbar guides">
  <div class="guideflexcontainer">
    <div class="docslink">
      <a class="returnlink" href="/version/2.13/guides/"> Back to Guides</a>
    </div>
    <div class="flexlabel">
      <label>By Version</label>
    </div>
    <div class="guidepulldown version">
    <select id="guide-version-dropdown">
      
        
        
        <option value="main" >Main - SNAPSHOT</option>
        
        
        
        <option value="latest" >3.16.2 - Latest</option>
        
        
        
        <option value="3.15" >3.15</option>
        
        
        
        <option value="3.8" >3.8</option>
        
        
        
        <option value="3.2" >3.2</option>
        
        
        
        <option value="2.16" >2.16</option>
        
        
        
        <option value="2.13" selected>2.13</option>
        </select>
    </div>
  </div>
</section>

<div class="guide">
  <div class="grid-wrapper">
    <div class="grid__item width-8-12 width-12-12-m">
      
      <h1 class="text-caps">Apache Kafka Reference Guide </h1>
      <div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>This reference guide demonstrates how your Quarkus application can utilize SmallRye Reactive Messaging to interact with Apache Kafka.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="introduction"><a class="anchor" href="#introduction"></a>1. Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="https://kafka.apache.org">Apache Kafka</a> is a popular open-source distributed event streaming platform.
It is used commonly for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.
Similar to a message queue, or an enterprise messaging platform, it lets you:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>publish</strong> (write) and <strong>subscribe</strong> to (read) streams of events, called <em>records</em>.</p>
</li>
<li>
<p><strong>store</strong> streams of records durably and reliably inside <em>topics</em>.</p>
</li>
<li>
<p><strong>process</strong> streams of records as they occur or retrospectively.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>And all this functionality is provided in a distributed, highly scalable, elastic, fault-tolerant, and secure manner.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="quarkus-extension-for-apache-kafka"><a class="anchor" href="#quarkus-extension-for-apache-kafka"></a>2. Quarkus Extension for Apache Kafka</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Quarkus provides support for Apache Kafka through <a href="https://smallrye.io/smallrye-reactive-messaging/">SmallRye Reactive Messaging</a> framework.
Based on Eclipse MicroProfile Reactive Messaging specification 2.0, it proposes a flexible programming model bridging CDI and event-driven.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>This guide provides an in-depth look on Apache Kafka and SmallRye Reactive Messaging framework.
For a quick start take a look at <a href="kafka-reactive-getting-started">Getting Started to SmallRye Reactive Messaging with Apache Kafka</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You can add the <code>smallrye-reactive-messaging-kafka</code> extensions to your project by running the following command in your project base directory:</p>
</div>
<div class="listingblock primary asciidoc-tabs-sync-cli">
<div class="title">CLI</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">quarkus extension add 'smallrye-reactive-messaging-kafka'</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-sync-maven">
<div class="title">Maven</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">./mvnw quarkus:add-extension -Dextensions='smallrye-reactive-messaging-kafka'</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-sync-gradle">
<div class="title">Gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">./gradlew addExtension --extensions='smallrye-reactive-messaging-kafka'</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will add the following to your build file:</p>
</div>
<div class="listingblock primary asciidoc-tabs-target-sync-cli asciidoc-tabs-target-sync-maven">
<div class="title">pom.xml</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.quarkus&lt;/groupId&gt;
    &lt;artifactId&gt;quarkus-smallrye-reactive-messaging-kafka&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-target-sync-gradle">
<div class="title">build.gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-gradle hljs" data-lang="gradle">implementation("io.quarkus:quarkus-smallrye-reactive-messaging-kafka")</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The extension includes <code>kafka-clients</code> version 3.2.1 as a transitive dependency and is compatible with Kafka brokers version 2.x.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="configuring-smallrye-kafka-connector"><a class="anchor" href="#configuring-smallrye-kafka-connector"></a>3. Configuring Smallrye Kafka Connector</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Because Smallrye Reactive Messaging framework supports different messaging backends like Apache Kafka, AMQP, Apache Camel, JMS, MQTT, etc., it employs a generic vocabulary:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Applications send and receive <strong>messages</strong>. A message wraps a <em>payload</em> and can be extended with some <em>metadata</em>. With the Kafka connector, a <em>message</em> corresponds to a Kafka <em>record</em>.</p>
</li>
<li>
<p>Messages transit on <strong>channels</strong>. Application components connect to channels to publish and consume messages. The Kafka connector maps <em>channels</em> to Kafka <em>topics</em>.</p>
</li>
<li>
<p>Channels are connected to message backends using <strong>connectors</strong>. Connectors are configured to map incoming messages to a specific channel (consumed by the application) and collect outgoing messages sent to a specific channel. Each connector is dedicated to a specific messaging technology. For example, the connector dealing with Kafka is named <code>smallrye-kafka</code>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>A minimal configuration for the Kafka connector with an incoming channel looks like the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">%prod.kafka.bootstrap.servers=kafka:9092 <i class="conum" data-value="1"></i><b>(1)</b>
mp.messaging.incoming.prices.connector=smallrye-kafka <i class="conum" data-value="2"></i><b>(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Configure the broker location for the production profile. You can configure it globally or per channel using <code>mp.messaging.incoming.$channel.bootstrap.servers</code> property.
In dev mode and when running tests, <a href="#kafka-dev-services">Dev Services for Kafka</a> automatically starts a Kafka broker.
When not provided this property defaults to <code>localhost:9092</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Configure the connector to manage the prices channel. By default, the topic name is same as the channel name. You can configure the topic attribute to override it.</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The <code>%prod</code> prefix indicates that the property is only used when the application runs in prod mode (so not in dev or test). Refer to the <a href="config-reference#profiles">Profile documentation</a> for further details.
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="title">Connector auto-attachment</div>
<div class="paragraph">
<p>If you have a single connector on your classpath, you can omit the <code>connector</code> attribute configuration.
Quarkus automatically associates <em>orphan</em> channels to the (unique) connector found on the classpath.
<em>Orphans</em> channels are outgoing channels without a downstream consumer or incoming channels without an upstream producer.</p>
</div>
<div class="paragraph">
<p>This auto-attachment can be disabled using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.reactive-messaging.auto-connector-attachment=false</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="receiving-messages-from-kafka"><a class="anchor" href="#receiving-messages-from-kafka"></a>4. Receiving messages from Kafka</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Continuing from the previous minimal configuration, your Quarkus application can receive message payload directly:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import org.eclipse.microprofile.reactive.messaging.Incoming;

import javax.enterprise.context.ApplicationScoped;

@ApplicationScoped
public class PriceConsumer {

    @Incoming("prices")
    public void consume(double price) {
        // process your price.
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>There are several other ways your application can consume incoming messages:</p>
</div>
<div class="listingblock">
<div class="title">Message</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public CompletionStage&lt;Void&gt; consume(Message&lt;Double&gt; msg) {
    // access record metadata
    var metadata = msg.getMetadata(IncomingKafkaRecordMetadata.class).orElseThrow();
    // process the message payload.
    double price = msg.getPayload();
    // Acknowledge the incoming message (commit the offset)
    return msg.ack();
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>Message</code> type lets the consuming method access the incoming message metadata and handle the acknowledgment manually.
We&#8217;ll explore different acknowledgment strategies in <a href="#commit-strategies">Commit Strategies</a>.</p>
</div>
<div class="paragraph">
<p>If you want to access the Kafka record objects directly, use:</p>
</div>
<div class="listingblock">
<div class="title">ConsumerRecord</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public void consume(ConsumerRecord&lt;String, Double&gt; record) {
    String key = record.key(); // Can be `null` if the incoming record has no key
    String value = record.value(); // Can be `null` if the incoming record has no value
    String topic = record.topic();
    int partition = record.partition();
    // ...
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>ConsumerRecord</code> is provided by the underlying Kafka client and can be injected directly to the consumer method.
Another simpler approach consists in using <code>Record</code>:</p>
</div>
<div class="listingblock">
<div class="title">Record</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public void consume(Record&lt;String, Double&gt; record) {
    String key = record.key(); // Can be `null` if the incoming record has no key
    String value = record.value(); // Can be `null` if the incoming record has no value
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>Record</code> is a simple wrapper around key and payload of the incoming Kafka record.</p>
</div>
<div class="paragraph">
<div class="title">@Channel</div>
<p>Alternatively, your application can inject a <code>Multi</code> in your bean and subscribe to its events as the following example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.mutiny.Multi;
import io.smallrye.reactive.messaging.annotations.Channel;

import javax.inject.Inject;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;
import org.jboss.resteasy.reactive.RestStreamElementType;

@Path("/prices")
public class PriceResource {

    @Inject
    @Channel("prices")
    Multi&lt;Double&gt; prices;

    @GET
    @Path("/prices")
    @RestStreamElementType(MediaType.TEXT_PLAIN)
    public Multi&lt;Double&gt; stream() {
        return prices;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>This is a good example of how to integrate a Kafka consumer with another downstream,
in this example exposing it as a Server-Sent Events endpoint.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>When consuming messages with <code>@Channel</code>, the application code is responsible for the subscription.
In the example above, the RESTEasy Reactive endpoint handles that for you.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Following types can be injected as channels:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Inject @Channel("prices") Multi&lt;Double&gt; streamOfPayloads;

@Inject @Channel("prices") Multi&lt;Message&lt;Double&gt;&gt; streamOfMessages;

@Inject @Channel("prices") Publisher&lt;Double&gt; publisherOfPayloads;

@Inject @Channel("prices") Publisher&lt;Message&lt;Double&gt;&gt; publisherOfMessages;</code></pre>
</div>
</div>
<div class="paragraph">
<p>As with the previous <code>Message</code> example, if your injected channel receives payloads (<code>Multi&lt;T&gt;</code>), it acknowledges the message automatically, and support multiple subscribers.
If you injected channel receives Message (<code>Multi&lt;Message&lt;T&gt;&gt;</code>), you will be responsible for the acknowledgment and broadcasting.
We will explore sending broadcast messages in <a href="#broadcasting-messages-on-multiple-consumers">Broadcasting messages on multiple consumers</a>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Injecting <code>@Channel("prices")</code> or having <code>@Incoming("prices")</code> does not automatically configure the application to consume messages from Kafka.
You need to configure an inbound connector with <code>mp.messaging.incoming.prices...</code> or have an <code>@Outgoing("prices")</code> method somewhere in your application (in which case, <code>prices</code> will be an in-memory channel).</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="blocking-processing"><a class="anchor" href="#blocking-processing"></a>4.1. Blocking processing</h3>
<div class="paragraph">
<p>Reactive Messaging invokes your method on an I/O thread.
See the <a href="quarkus-reactive-architecture">Quarkus Reactive Architecture documentation</a> for further details on this topic.
But, you often need to combine Reactive Messaging with blocking processing such as database interactions.
For this, you need to use the <code>@Blocking</code> annotation indicating that the processing is <em>blocking</em> and should not be run on the caller thread.</p>
</div>
<div class="paragraph">
<p>For example, The following code illustrates how you can store incoming payloads to a database using Hibernate with Panache:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.reactive.messaging.annotations.Blocking;
import org.eclipse.microprofile.reactive.messaging.Incoming;

import javax.enterprise.context.ApplicationScoped;
import javax.transaction.Transactional;

@ApplicationScoped
public class PriceStorage {

    @Incoming("prices")
    @Transactional
    public void store(int priceInUsd) {
        Price price = new Price();
        price.value = priceInUsd;
        price.persist();
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The complete example is available in the <code>kafka-panache-quickstart</code> <a href="https://github.com/quarkusio/quarkus-quickstarts/tree/main/kafka-panache-quickstart">directory</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>There are 2 <code>@Blocking</code> annotations:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>io.smallrye.reactive.messaging.annotations.Blocking</code></p>
</li>
<li>
<p><code>io.smallrye.common.annotation.Blocking</code></p>
</li>
</ol>
</div>
<div class="paragraph">
<p>They have the same effect.
Thus, you can use both.
The first one provides more fine-grained tuning such as the worker pool to use and whether it preserves the order.
The second one, used also with other reactive features of Quarkus, uses the default worker pool and preserves the order.</p>
</div>
<div class="paragraph">
<p>Detailed information on the usage of <code>@Blocking</code> annotation can be found in <a href="https://smallrye.io/smallrye-reactive-messaging/latest/concepts/blocking/">SmallRye Reactive Messaging – Handling blocking execution</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="title">@Transactional</div>
<div class="paragraph">
<p>If your method is annotated with <code>@Transactional</code>, it will be considered <em>blocking</em> automatically, even if the method is not annotated with <code>@Blocking</code>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="acknowledgment-strategies"><a class="anchor" href="#acknowledgment-strategies"></a>4.2. Acknowledgment Strategies</h3>
<div class="paragraph">
<p>All messages received by a consumer must be acknowledged.
In the absence of acknowledgment, the processing is considered in error.
If the consumer method receives a <code>Record</code> or a payload, the message will be acked on method return, also known as <code>Strategy.POST_PROCESSING</code>.
If the consumer method returns another reactive stream or <code>CompletionStage</code>, the message will be acked when the downstream message is acked.
You can override the default behavior to ack the message on arrival (<code>Strategy.PRE_PROCESSING</code>),
or do not ack the message at all (<code>Strategy.NONE</code>) on the consumer method as in the following example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
@Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING)
public void process(double price) {
    // process price
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>If the consumer method receives a <code>Message</code>, the acknowledgment strategy is <code>Strategy.MANUAL</code>
and the consumer method is in charge of ack/nack the message.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public CompletionStage&lt;Void&gt; process(Message&lt;Double&gt; msg) {
    // process price
    return msg.ack();
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>As mentioned above, the method can also override the acknowledgment strategy to <code>PRE_PROCESSING</code> or <code>NONE</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="commit-strategies"><a class="anchor" href="#commit-strategies"></a>4.3. Commit Strategies</h3>
<div class="paragraph">
<p>When a message produced from a Kafka record is acknowledged, the connector invokes a commit strategy.
These strategies decide when the consumer offset for a specific topic/partition is committed.
Committing an offset indicates that all previous records have been processed.
It is also the position where the application would restart the processing after a crash recovery or a restart.</p>
</div>
<div class="paragraph">
<p>Committing every offset has performance penalties as Kafka offset management can be slow.
However, not committing the offset often enough may lead to message duplication if the application crashes between two commits.</p>
</div>
<div class="paragraph">
<p>The Kafka connector supports three strategies:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>throttled</code> keeps track of received messages and commits an offset of the latest acked message in sequence (meaning, all previous messages were also acked).
This strategy guarantees at-least-once delivery even if the channel performs asynchronous processing.
The connector tracks the received records and periodically (period specified by <code>auto.commit.interval.ms</code>, default: 5000 ms) commits the highest consecutive offset.
The connector will be marked as unhealthy if a message associated with a record is not acknowledged in <code>throttled.unprocessed-record-max-age.ms</code> (default: 60000 ms).
Indeed, this strategy cannot commit the offset as soon as a single record processing fails (see <a href="#error-handling">Error Handling Strategies</a> to configure what happens on failing processing).
If <code>throttled.unprocessed-record-max-age.ms</code> is set to less than or equal to <code>0</code>, it does not perform any health check verification.
Such a setting might lead to running out of memory if there are "poison pill" messages (that are never acked).
This strategy is the default if <code>enable.auto.commit</code> is not explicitly set to true.</p>
</li>
<li>
<p><code>latest</code> commits the record offset received by the Kafka consumer as soon as the associated message is acknowledged (if the offset is higher than the previously committed offset).
This strategy provides at-least-once delivery if the channel processes the message without performing any asynchronous processing.
This strategy should not be used in high load environment, as offset commit is expensive. However, it reduces the risk of duplicates.</p>
</li>
<li>
<p><code>ignore</code> performs no commit. This strategy is the default strategy when the consumer is explicitly configured with <code>enable.auto.commit</code> to true.
It delegates the offset commit to the underlying Kafka client.
When <code>enable.auto.commit</code> is <code>true</code> this strategy <strong>DOES NOT</strong> guarantee at-least-once delivery.
SmallRye Reactive Messaging processes records asynchronously, so offsets may be committed for records that have been polled but not yet processed.
In case of a failure, only records that were not committed yet will be re-processed.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The Kafka connector disables the Kafka auto commit when it is not explicitly enabled. This behavior differs from the traditional Kafka consumer.
If high throughput is important for you, and you are not limited by the downstream, we recommend to either:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>use the <code>throttled</code> policy,</p>
</li>
<li>
<p>or set <code>enable.auto.commit</code> to true and annotate the consuming method with <code>@Acknowledgment(Acknowledgment.Strategy.NONE)</code>.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Smallrye Reactive Messaging enables implementing custom commit strategies.
See <a href="https://smallrye.io/smallrye-reactive-messaging/latest/kafka/receiving-kafka-records/#acknowledgement">SmallRye Reactive Messaging documentation</a> for more information.</p>
</div>
</div>
<div class="sect2">
<h3 id="error-handling"><a class="anchor" href="#error-handling"></a>4.4. Error Handling Strategies</h3>
<div class="paragraph">
<p>If a message produced from a Kafka record is nacked, a failure strategy is applied. The Kafka connector supports three strategies:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>fail</code>: fail the application, no more records will be processed (default strategy). The offset of the record that has not been processed correctly is not committed.</p>
</li>
<li>
<p><code>ignore</code>: the failure is logged, but the processing continue. The offset of the record that has not been processed correctly is committed.</p>
</li>
<li>
<p><code>dead-letter-queue</code>: the offset of the record that has not been processed correctly is committed, but the record is written to a Kafka dead letter topic.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The strategy is selected using the <code>failure-strategy</code> attribute.</p>
</div>
<div class="paragraph">
<p>In the case of <code>dead-letter-queue</code>, you can configure the following attributes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>dead-letter-queue.topic</code>: the topic to use to write the records not processed correctly, default is <code>dead-letter-topic-$channel</code>, with <code>$channel</code> being the name of the channel.</p>
</li>
<li>
<p><code>dead-letter-queue.key.serializer</code>: the serializer used to write the record key on the dead letter queue. By default, it deduces the serializer from the key deserializer.</p>
</li>
<li>
<p><code>dead-letter-queue.value.serializer</code>: the serializer used to write the record value on the dead letter queue. By default, it deduces the serializer from the value deserializer.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The record written on the dead letter queue contains a set of additional headers about the original record:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>dead-letter-reason</strong>: the reason of the failure</p>
</li>
<li>
<p><strong>dead-letter-cause</strong>: the cause of the failure if any</p>
</li>
<li>
<p><strong>dead-letter-topic</strong>: the original topic of the record</p>
</li>
<li>
<p><strong>dead-letter-partition</strong>: the original partition of the record (integer mapped to String)</p>
</li>
<li>
<p><strong>dead-letter-offset</strong>: the original offset of the record (long mapped to String)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Smallrye Reactive Messaging enables implementing custom failure strategies.
See <a href="https://smallrye.io/smallrye-reactive-messaging/latest/kafka/receiving-kafka-records/#acknowledgement">SmallRye Reactive Messaging documentation</a> for more information.</p>
</div>
<div class="sect3">
<h4 id="retrying-processing"><a class="anchor" href="#retrying-processing"></a>4.4.1. Retrying processing</h4>
<div class="paragraph">
<p>You can combine Reactive Messaging with <a href="https://github.com/smallrye/smallrye-fault-tolerance">SmallRye Fault Tolerance</a>, and retry processing if it failed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("kafka")
@Retry(delay = 10, maxRetries = 5)
public void consume(String v) {
   // ... retry if this method throws an exception
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can configure the delay, the number of retries, the jitter, etc.</p>
</div>
<div class="paragraph">
<p>If your method returns a <code>Uni</code> or <code>CompletionStage</code>, you need to add the <code>@NonBlocking</code> annotation:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("kafka")
@Retry(delay = 10, maxRetries = 5)
@NonBlocking
public Uni&lt;String&gt; consume(String v) {
   // ... retry if this method throws an exception or the returned Uni produce a failure
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The <code>@NonBlocking</code> annotation is only required with SmallRye Fault Tolerance 5.1.0 and earlier.
Starting with SmallRye Fault Tolerance 5.2.0 (available since Quarkus 2.1.0.Final), it is not necessary.
See <a href="https://smallrye.io/docs/smallrye-fault-tolerance/5.2.0/usage/extra.html#_non_compatible_mode">SmallRye Fault Tolerance documentation</a> for more information.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The incoming messages are acknowledged only once the processing completes successfully.
So, it commits the offset after the successful processing.
If the processing still fails, even after all retries, the message is <em>nacked</em> and the failure strategy is applied.</p>
</div>
</div>
<div class="sect3">
<h4 id="handling-deserialization-failures"><a class="anchor" href="#handling-deserialization-failures"></a>4.4.2. Handling Deserialization Failures</h4>
<div class="paragraph">
<p>When a deserialization failure occurs, you can intercept it and provide a failure strategy.
To achieve this, you need to create a bean implementing <code>DeserializationFailureHandler&lt;T&gt;</code> interface:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@ApplicationScoped
@Identifier("failure-retry") // Set the name of the failure handler
public class MyDeserializationFailureHandler
    implements DeserializationFailureHandler&lt;JsonObject&gt; { // Specify the expected type

    @Override
    public JsonObject decorateDeserialization(Uni&lt;JsonObject&gt; deserialization, String topic, boolean isKey,
            String deserializer, byte[] data, Headers headers) {
        return deserialization
                    .onFailure().retry().atMost(3)
                    .await().atMost(Duration.ofMillis(200));
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>To use this failure handler, the bean must be exposed with the <code>@Identifier</code> qualifier and the connector configuration must specify the attribute <code>mp.messaging.incoming.$channel.[key|value]-deserialization-failure-handler</code> (for key or value deserializers).</p>
</div>
<div class="paragraph">
<p>The handler is called with details of the deserialization, including the action represented as <code>Uni&lt;T&gt;</code>.
On the deserialization <code>Uni</code> failure strategies like retry, providing a fallback value or applying timeout can be implemented.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="consumer-groups"><a class="anchor" href="#consumer-groups"></a>4.5. Consumer Groups</h3>
<div class="paragraph">
<p>In Kafka, a consumer group is a set of consumers which cooperate to consume data from a topic.
A topic is divided into a set of partitions.
The partitions of a topic are assigned among the consumers in the group, effectively allowing to scale consumption throughput.
Note that each partition is assigned to a single consumer from a group.
However, a consumer can be assigned multiple partitions if the number of partitions is greater than the number of consumer in the group.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s explore briefly different producer/consumer patterns and how to implement them using Quarkus:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Single consumer thread inside a consumer group</strong></p>
<div class="paragraph">
<p>This is the default behavior of an application subscribing to a Kafka topic: Each Kafka connector will create a single consumer thread and place it inside a single consumer group.
Consumer group id defaults to the application name as set by the <code>quarkus.application.name</code> configuration property.
It can also be set using the <code>kafka.group.id</code> property.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-one-app-one-consumer.png" alt="Architecture" width="60%">
</div>
</div>
</li>
<li>
<p><strong>Multiple consumer threads inside a consumer group</strong></p>
<div class="paragraph">
<p>For a given application instance, the number of consumers inside the consumer group can be configured using <code>mp.messaging.incoming.$channel.partitions</code> property.
The partitions of the subscribed topic will be divided among the consumer threads.
Note that if the <code>partitions</code> value exceed the number of partitions of the topic, some consumer threads won&#8217;t be assigned any partitions.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-one-app-two-consumers.png" alt="Architecture" width="60%">
</div>
</div>
</li>
<li>
<p><strong>Multiple consumer applications inside a consumer group</strong></p>
<div class="paragraph">
<p>Similar to the previous example, multiple instances of an application can subscribe to a single consumer group, configured via <code>mp.messaging.incoming.$channel.group.id</code> property, or left default to the application name.
This in turn will divide partitions of the topic among application instances.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-two-app-one-consumer-group.png" alt="Architecture" width="60%">
</div>
</div>
</li>
<li>
<p><strong>Pub/Sub: Multiple consumer groups subscribed to a topic</strong></p>
<div class="paragraph">
<p>Lastly different applications can subscribe independently to same topics using different <strong>consumer group ids</strong>.
For example, messages published to a topic called <em>orders</em> can be consumed independently on two consumer applications, one with <code>mp.messaging.incoming.orders.group.id=invoicing</code> and second with <code>mp.messaging.incoming.orders.group.id=shipping</code>.
Different consumer groups can thus scale independently according to the message consumption requirements.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-two-app-two-consumer-groups.png" alt="Architecture" width="60%">
</div>
</div>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>A common business requirement is to consume and process Kafka records in order.
The Kafka broker preserves order of records inside a partition and not inside a topic.
Therefore, it is important to think about how records are partitioned inside a topic.
The default partitioner uses record key hash to compute the partition for a record, or when the key is not defined, chooses a partition randomly per batch or records.</p>
</div>
<div class="paragraph">
<p>During normal operation, a Kafka consumer preserves the order of records inside each partition assigned to it.
Smallrye Reactive Messaging keeps this order for processing, unless <code>@Blocking(ordered = false)</code> is used (see <a href="#blocking-processing">Blocking processing</a>).</p>
</div>
<div class="paragraph">
<p>Note that due to consumer rebalances, Kafka consumers only guarantee at-least-once processing of single records, meaning that uncommitted records <em>can</em> be processed again by consumers.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="consumer-rebalance-listener"><a class="anchor" href="#consumer-rebalance-listener"></a>4.5.1. Consumer Rebalance Listener</h4>
<div class="paragraph">
<p>Inside a consumer group, as new group members arrive and old members leave, the partitions are re-assigned so that each member receives a proportional share of the partitions.
This is known as rebalancing the group.
To handle offset commit and assigned partitions yourself, you can provide a consumer rebalance listener.
To achieve this, implement the <code>io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener</code> interface and expose it as a CDI bean with the <code>@Idenfier</code> qualifier.
A common use case is to store offset in a separate data store to implement exactly-once semantic, or starting the processing at a specific offset.</p>
</div>
<div class="paragraph">
<p>The listener is invoked every time the consumer topic/partition assignment changes.
For example, when the application starts, it invokes the <code>partitionsAssigned</code> callback with the initial set of topics/partitions associated with the consumer.
If, later, this set changes, it calls the <code>partitionsRevoked</code> and <code>partitionsAssigned</code> callbacks again, so you can implement custom logic.</p>
</div>
<div class="paragraph">
<p>Note that the rebalance listener methods are called from the Kafka polling thread and <strong>will</strong> block the caller thread until completion.
That’s because the rebalance protocol has synchronization barriers, and using asynchronous code in a rebalance listener may be executed after the synchronization barrier.</p>
</div>
<div class="paragraph">
<p>When topics/partitions are assigned or revoked from a consumer, it pauses the message delivery and resumes once the rebalance completes.</p>
</div>
<div class="paragraph">
<p>If the rebalance listener handles offset commit on behalf of the user (using the <code>NONE</code> commit strategy),
the rebalance listener must commit the offset synchronously in the partitionsRevoked callback.
We also recommend applying the same logic when the application stops.</p>
</div>
<div class="paragraph">
<p>Unlike the <code>ConsumerRebalanceListener</code> from Apache Kafka, the <code>io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener</code> methods pass the Kafka Consumer and the set of topics/partitions.</p>
</div>
<div class="paragraph">
<p>In the following example we set up a consumer that always starts on messages from at most 10 minutes ago (or offset 0).
First we need to provide a bean that implements <code>io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener</code> and is annotated with <code>io.smallrye.common.annotation.Identifier</code>.
We then must configure our inbound connector to use this bean.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package inbound;

import io.smallrye.common.annotation.Identifier;
import io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener;
import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.consumer.OffsetAndTimestamp;
import org.apache.kafka.clients.consumer.TopicPartition;

import javax.enterprise.context.ApplicationScoped;
import java.util.Collection;
import java.util.HashMap;
import java.util.Map;
import java.util.logging.Logger;

@ApplicationScoped
@Identifier("rebalanced-example.rebalancer")
public class KafkaRebalancedConsumerRebalanceListener implements KafkaConsumerRebalanceListener {

    private static final Logger LOGGER = Logger.getLogger(KafkaRebalancedConsumerRebalanceListener.class.getName());

    /**
     * When receiving a list of partitions, will search for the earliest offset within 10 minutes
     * and seek the consumer to it.
     *
     * @param consumer   underlying consumer
     * @param partitions set of assigned topic partitions
     */
    @Override
    public void onPartitionsAssigned(Consumer&lt;?, ?&gt; consumer, Collection&lt;TopicPartition&gt; partitions) {
        long now = System.currentTimeMillis();
        long shouldStartAt = now - 600_000L; //10 minute ago

        Map&lt;TopicPartition, Long&gt; request = new HashMap&lt;&gt;();
        for (TopicPartition partition : partitions) {
            LOGGER.info("Assigned " + partition);
            request.put(partition, shouldStartAt);
        }
        Map&lt;TopicPartition, OffsetAndTimestamp&gt; offsets = consumer.offsetsForTimes(request);
        for (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; position : offsets.entrySet()) {
            long target = position.getValue() == null ? 0L : position.getValue().offset();
            LOGGER.info("Seeking position " + target + " for " + position.getKey());
            consumer.seek(position.getKey(), target);
        }
    }

}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package inbound;

import io.smallrye.reactive.messaging.kafka.IncomingKafkaRecord;
import org.eclipse.microprofile.reactive.messaging.Acknowledgment;
import org.eclipse.microprofile.reactive.messaging.Incoming;

import javax.enterprise.context.ApplicationScoped;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.CompletionStage;

@ApplicationScoped
public class KafkaRebalancedConsumer {

    @Incoming("rebalanced-example")
    @Acknowledgment(Acknowledgment.Strategy.NONE)
    public CompletionStage&lt;Void&gt; consume(IncomingKafkaRecord&lt;Integer, String&gt; message) {
        // We don't need to ACK messages because in this example,
        // we set offset during consumer rebalance
        return CompletableFuture.completedFuture(null);
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>To configure the inbound connector to use the provided listener, we either set the consumer rebalance listener’s identifier:
<code>mp.messaging.incoming.rebalanced-example.consumer-rebalance-listener.name=rebalanced-example.rebalancer</code></p>
</div>
<div class="paragraph">
<p>Or have the listener’s name be the same as the group id:</p>
</div>
<div class="paragraph">
<p><code>mp.messaging.incoming.rebalanced-example.group.id=rebalanced-example.rebalancer</code></p>
</div>
<div class="paragraph">
<p>Setting the consumer rebalance listener’s name takes precedence over using the group id.</p>
</div>
</div>
<div class="sect3">
<h4 id="using-unique-consumer-groups"><a class="anchor" href="#using-unique-consumer-groups"></a>4.5.2. Using unique consumer groups</h4>
<div class="paragraph">
<p>If you want to process all the records from a topic (from its beginning), you need:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>to set <code>auto.offset.reset = earliest</code></p>
</li>
<li>
<p>assign your consumer to a consumer group not used by any other application.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Quarkus generates a UUID that changes between two executions (including in dev mode).
So, you are sure no other consumer uses it, and you receive a new unique group id every time your application starts.</p>
</div>
<div class="paragraph">
<p>You can use that generated UUID as the consumer group as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.your-channel.auto.offset.reset=earliest
mp.messaging.incoming.your-channel.group.id=${quarkus.uuid}</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
If the <code>group.id</code> attribute is not set, it defaults the <code>quarkus.application.name</code> configuration property.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="receiving-kafka-records-in-batches"><a class="anchor" href="#receiving-kafka-records-in-batches"></a>4.6. Receiving Kafka Records in Batches</h3>
<div class="paragraph">
<p>By default, incoming methods receive each Kafka record individually.
Under the hood, Kafka consumer clients poll the broker constantly and receive records in batches, presented inside the <code>ConsumerRecords</code> container.</p>
</div>
<div class="paragraph">
<p>In <strong>batch</strong> mode, your application can receive all the records returned by the consumer <strong>poll</strong> in one go.</p>
</div>
<div class="paragraph">
<p>To achieve this you need to specify a compatible container type to receive all the data:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public void consume(List&lt;Double&gt; prices) {
    for (double price : prices) {
        // process price
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The incoming method can also receive <code>Message&lt;List&lt;Payload&gt;&gt;</code>, <code>KafkaRecordBatch&lt;Key, Payload&gt;</code> <code>ConsumerRecords&lt;Key, Payload&gt;</code> types.
They give access to record details such as offset or timestamp:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("prices")
public CompletionStage&lt;Void&gt; consumeMessage(KafkaRecordBatch&lt;String, Double&gt; records) {
    for (KafkaRecord&lt;String, Double&gt; record : records) {
        String payload = record.getPayload();
        String topic = record.getTopic();
        // process messages
    }
    // ack will commit the latest offsets (per partition) of the batch.
    return records.ack();
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note that the successful processing of the incoming record batch will commit the latest offsets for each partition received inside the batch.
The configured commit strategy will be applied for these records only.</p>
</div>
<div class="paragraph">
<p>Conversely, if the processing throws an exception, all messages are <em>nacked</em>, applying the failure strategy for all the records inside the batch.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Quarkus autodetects batch types for incoming channels and sets batch configuration automatically.
You can configure batch mode explicitly with <code>mp.messaging.incoming.$channel.batch</code> property.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sending-messages-to-kafka"><a class="anchor" href="#sending-messages-to-kafka"></a>5. Sending messages to Kafka</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Configuration for the Kafka connector outgoing channels is similar to that of incoming:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">%prod.kafka.bootstrap.servers=kafka:9092 <i class="conum" data-value="1"></i><b>(1)</b>
mp.messaging.outgoing.prices-out.connector=smallrye-kafka <i class="conum" data-value="2"></i><b>(2)</b>
mp.messaging.outgoing.prices-out.topic=prices <i class="conum" data-value="3"></i><b>(3)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Configure the broker location for the production profile. You can configure it globally or per channel using <code>mp.messaging.outgoing.$channel.bootstrap.servers</code> property.
In dev mode and when running tests, <a href="#kafka-dev-services">Dev Services for Kafka</a> automatically starts a Kafka broker.
When not provided, this property defaults to <code>localhost:9092</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Configure the connector to manage the <code>prices-out</code> channel.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>By default, the topic name is same as the channel name. You can configure the topic attribute to override it.</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Inside application configuration, channel names are unique.
Therefore, if you&#8217;d like to configure an incoming and outgoing channel on the same topic, you will need to name channels differently (like in the examples of this guide, <code>mp.messaging.incoming.prices</code> and <code>mp.messaging.outgoing.prices-out</code>).</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Then, your application can generate messages and publish them to the <code>prices-out</code> channel.
It can use <code>double</code> payloads as in the following snippet:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.mutiny.Multi;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import javax.enterprise.context.ApplicationScoped;
import java.time.Duration;
import java.util.Random;

@ApplicationScoped
public class KafkaPriceProducer {

    private final Random random = new Random();

    @Outgoing("prices-out")
    public Multi&lt;Double&gt; generate() {
        // Build an infinite stream of random prices
        // It emits a price every second
        return Multi.createFrom().ticks().every(Duration.ofSeconds(1))
            .map(x -&gt; random.nextDouble());
    }

}</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>You should not call methods annotated with <code>@Incoming</code> and/or <code>@Outgoing</code> directly from your code. They are invoked by the framework. Having user code invoking them would not have the expected outcome.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Note that the <code>generate</code> method returns a <code>Multi&lt;Double&gt;</code>, which implements the Reactive Streams <code>Publisher</code> interface.
This publisher will be used by the framework to generate messages and send them to the configured Kafka topic.</p>
</div>
<div class="paragraph">
<p>Instead of returning a payload, you can return a <code>io.smallrye.reactive.messaging.kafka.Record</code> to send key/value pairs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Outgoing("out")
public Multi&lt;Record&lt;String, Double&gt;&gt; generate() {
    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))
        .map(x -&gt; Record.of("my-key", random.nextDouble()));
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Payload can be wrapped inside <code>org.eclipse.microprofile.reactive.messaging.Message</code> to have more control on the written records:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Outgoing("generated-price")
public Multi&lt;Message&lt;Double&gt;&gt; generate() {
    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))
            .map(x -&gt; Message.of(random.nextDouble())
                    .addMetadata(OutgoingKafkaRecordMetadata.&lt;String&gt;builder()
                            .withKey("my-key")
                            .withTopic("my-key-prices")
                            .withHeaders(new RecordHeaders().add("my-header", "value".getBytes()))
                            .build()));
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>OutgoingKafkaRecordMetadata</code> allows to set metadata attributes of the Kafka record, such as <code>key</code>, <code>topic</code>, <code>partition</code> or <code>timestamp</code>.
One use case is to dynamically select the destination topic of a message.
In this case, instead of configuring the topic inside your application configuration file, you need to use the outgoing metadata to set the name of the topic.</p>
</div>
<div class="paragraph">
<p>Other than method signatures returning a Reactive Stream <code>Publisher</code> (<code>Multi</code> being an implementation of <code>Publisher</code>), outgoing method can also return single message.
In this case the producer will use this method as generator to create an infinite stream.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Outgoing("prices-out") T generate(); // T excluding void

@Outgoing("prices-out") Message&lt;T&gt; generate();

@Outgoing("prices-out") Uni&lt;T&gt; generate();

@Outgoing("prices-out") Uni&lt;Message&lt;T&gt;&gt; generate();

@Outgoing("prices-out") CompletionStage&lt;T&gt; generate();

@Outgoing("prices-out") CompletionStage&lt;Message&lt;T&gt;&gt; generate();</code></pre>
</div>
</div>
<div class="sect2">
<h3 id="sending-messages-with-emitter"><a class="anchor" href="#sending-messages-with-emitter"></a>5.1. Sending messages with @Emitter</h3>
<div class="paragraph">
<p>Sometimes, you need to have an imperative way of sending messages.</p>
</div>
<div class="paragraph">
<p>For example, if you need to send a message to a stream when receiving a POST request inside a REST endpoint.
In this case, you cannot use <code>@Outgoing</code> because your method has parameters.</p>
</div>
<div class="paragraph">
<p>For this, you can use an <code>Emitter</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

import javax.inject.Inject;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Consumes;
import javax.ws.rs.core.MediaType;

@Path("/prices")
public class PriceResource {

    @Inject
    @Channel("price-create")
    Emitter&lt;Double&gt; priceEmitter;

    @POST
    @Consumes(MediaType.TEXT_PLAIN)
    public void addPrice(Double price) {
        CompletionStage&lt;Void&gt; ack = priceEmitter.send(price);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Sending a payload returns a <code>CompletionStage</code>, completed when the message is acked. If the message transmission fails, the <code>CompletionStage</code> is completed exceptionally with the reason of the nack.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The <code>Emitter</code> configuration is done the same way as the other stream configuration used by <code>@Incoming</code> and <code>@Outgoing</code>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Using the <code>Emitter</code> you are sending messages from your imperative code to reactive messaging.
These messages are stored in a queue until they are sent.
If the Kafka producer client can&#8217;t keep up with messages trying to be sent over to Kafka, this queue can become a memory hog and you may even run out of memory.
You can use <code>@OnOverflow</code> to configure back-pressure strategy.
It lets you configure the size of the queue (default is 256) and the strategy to apply when the buffer size is reached. Available strategies are <code>DROP</code>, <code>LATEST</code>, <code>FAIL</code>, <code>BUFFER</code>, <code>UNBOUNDED_BUFFER</code> and <code>NONE</code>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>With the <code>Emitter</code> API, you can also encapsulate the outgoing payload inside <code>Message&lt;T&gt;</code>. As with the previous examples, <code>Message</code> lets you handle the ack/nack cases differently.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.concurrent.CompletableFuture;
import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

import javax.inject.Inject;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Consumes;
import javax.ws.rs.core.MediaType;

@Path("/prices")
public class PriceResource {

    @Inject @Channel("price-create") Emitter&lt;Double&gt; priceEmitter;

    @POST
    @Consumes(MediaType.TEXT_PLAIN)
    public void addPrice(Double price) {
        priceEmitter.send(Message.of(price)
            .withAck(() -&gt; {
                // Called when the message is acked
                return CompletableFuture.completedFuture(null);
            })
            .withNack(throwable -&gt; {
                // Called when the message is nacked
                return CompletableFuture.completedFuture(null);
            }));
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you prefer using Reactive Stream APIs, you can use <code>MutinyEmitter</code> that will return <code>Uni&lt;Void&gt;</code> from the <code>send</code> method.
You can therefore use Mutiny APIs for handling downstream messages and errors.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import org.eclipse.microprofile.reactive.messaging.Channel;

import javax.inject.Inject;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Consumes;
import javax.ws.rs.core.MediaType;

import io.smallrye.reactive.messaging.MutinyEmitter;

@Path("/prices")
public class PriceResource {

    @Inject
    @Channel("price-create")
    MutinyEmitter&lt;Double&gt; priceEmitter;

    @POST
    @Consumes(MediaType.TEXT_PLAIN)
    public Uni&lt;String&gt; addPrice(Double price) {
        return quoteRequestEmitter.send(price)
                .map(x -&gt; "ok")
                .onFailure().recoverWithItem("ko");
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>It is also possible to block on sending the event to the emitter with the <code>sendAndAwait</code> method.
It will only return from the method when the event is acked or nacked by the receiver.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">Deprecation</div>
<div class="paragraph">
<p>The <code>io.smallrye.reactive.messaging.annotations.Emitter</code>, <code>io.smallrye.reactive.messaging.annotations.Channel</code> and <code>io.smallrye.reactive.messaging.annotations.OnOverflow</code> classes are now deprecated and replaced by:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>org.eclipse.microprofile.reactive.messaging.Emitter</code></p>
</li>
<li>
<p><code>org.eclipse.microprofile.reactive.messaging.Channel</code></p>
</li>
<li>
<p><code>org.eclipse.microprofile.reactive.messaging.OnOverflow</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The new <code>Emitter.send</code> method returns a <code>CompletionStage</code> completed when the produced message is acknowledged.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="title">Depreciation</div>
<div class="paragraph">
<p><code>MutinyEmitter#send(Message msg)</code> method is deprecated in favor of following methods receiving <code>Message</code> for emitting:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>&lt;M extends Message&lt;? extends T&gt;&gt; Uni&lt;Void&gt; sendMessage(M msg)</code></p>
</li>
<li>
<p><code>&lt;M extends Message&lt;? extends T&gt;&gt; void sendMessageAndAwait(M msg)</code></p>
</li>
<li>
<p><code>&lt;M extends Message&lt;? extends T&gt;&gt; Cancellable sendMessageAndForget(M msg)</code></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>More information on how to use <code>Emitter</code> can be found in <a href="https://smallrye.io/smallrye-reactive-messaging/latest/concepts/emitter/">SmallRye Reactive Messaging – Emitters and Channels</a></p>
</div>
</div>
<div class="sect2">
<h3 id="write-acknowledgement"><a class="anchor" href="#write-acknowledgement"></a>5.2. Write Acknowledgement</h3>
<div class="paragraph">
<p>When Kafka broker receives a record, its acknowledgement can take time depending on the configuration.
Also, it stores in-memory the records that cannot be written.</p>
</div>
<div class="paragraph">
<p>By default, the connector does wait for Kafka to acknowledge the record to continue the processing (acknowledging the received Message).
You can disable this by setting the <code>waitForWriteCompletion</code> attribute to <code>false</code>.</p>
</div>
<div class="paragraph">
<p>Note that the <code>acks</code> attribute has a huge impact on the record acknowledgement.</p>
</div>
<div class="paragraph">
<p>If a record cannot be written, the message is nacked.</p>
</div>
</div>
<div class="sect2">
<h3 id="backpressure"><a class="anchor" href="#backpressure"></a>5.3. Backpressure</h3>
<div class="paragraph">
<p>The Kafka outbound connector handles back-pressure, monitoring the number of in-flight messages waiting to be written to the Kafka broker.
The number of in-flight messages is configured using the <code>max-inflight-messages</code> attribute and defaults to 1024.</p>
</div>
<div class="paragraph">
<p>The connector only sends that amount of messages concurrently.
No other messages will be sent until at least one in-flight message gets acknowledged by the broker.
Then, the connector writes a new message to Kafka when one of the broker’s in-flight messages get acknowledged.
Be sure to configure Kafka’s <code>batch.size</code> and <code>linger.ms</code> accordingly.</p>
</div>
<div class="paragraph">
<p>You can also remove the limit of in-flight messages by setting <code>max-inflight-messages</code> to <code>0</code>.
However, note that the Kafka producer may block if the number of requests reaches <code>max.in.flight.requests.per.connection</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="retrying-message-dispatch"><a class="anchor" href="#retrying-message-dispatch"></a>5.4. Retrying message dispatch</h3>
<div class="paragraph">
<p>When the Kafka producer receives an error from the server, if it is a transient, recoverable error, the client will retry sending the batch of messages.
This behavior is controlled by <code>retries</code> and <code>retry.backoff.ms</code> parameters.
In addition to this, SmallRye Reactive Messaging will retry individual messages on recoverable errors, depending on the <code>retries</code> and <code>delivery.timeout.ms</code> parameters.</p>
</div>
<div class="paragraph">
<p>Note that while having retries in a reliable system is a best practice, the <code>max.in.flight.requests.per.connection</code> parameter defaults to <code>5</code>, meaning that the order of the messages is not guaranteed.
If the message order is a must for your use case, setting <code>max.in.flight.requests.per.connection</code> to <code>1</code> will make sure a single batch of messages is sent at a time, in the expense of limiting the throughput of the producer.</p>
</div>
<div class="paragraph">
<p>For applying retry mechanism on processing errors, see the section on <a href="#retrying-processing">Retrying processing</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="handling-serialization-failures"><a class="anchor" href="#handling-serialization-failures"></a>5.5. Handling Serialization Failures</h3>
<div class="paragraph">
<p>For Kafka producer client serialization failures are not recoverable, thus the message dispatch is not retried. In these cases you may need to apply a failure strategy for the serializer.
To achieve this, you need to create a bean implementing <code>SerializationFailureHandler&lt;T&gt;</code> interface:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@ApplicationScoped
@Identifier("failure-fallback") // Set the name of the failure handler
public class MySerializationFailureHandler
    implements SerializationFailureHandler&lt;JsonObject&gt; { // Specify the expected type

    @Override
    public byte[] decorateSerialization(Uni&lt;byte[]&gt; serialization, String topic, boolean isKey,
        String serializer, Object data, Headers headers) {
        return serialization
                    .onFailure().retry().atMost(3)
                    .await().indefinitely();
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>To use this failure handler, the bean must be exposed with the <code>@Identifier</code> qualifier and the connector configuration must specify the attribute <code>mp.messaging.outgoing.$channel.[key|value]-serialization-failure-handler</code> (for key or value serializers).</p>
</div>
<div class="paragraph">
<p>The handler is called with details of the serialization, including the action represented as <code>Uni&lt;byte[]&gt;</code>.
Note that the method must await on the result and return the serialized byte array.</p>
</div>
</div>
<div class="sect2">
<h3 id="in-memory-channels"><a class="anchor" href="#in-memory-channels"></a>5.6. In-memory channels</h3>
<div class="paragraph">
<p>In some use cases, it is convenient to use the messaging patterns to transfer messages inside the same application.
When you don&#8217;t connect a channel to a messaging backend like Kafka, everything happens in-memory, and the streams are created by chaining methods together.
Each chain is still a reactive stream and enforces the back-pressure protocol.</p>
</div>
<div class="paragraph">
<p>The framework verifies that the producer/consumer chain is complete,
meaning that if the application writes messages into an in-memory channel (using a method with only <code>@Outgoing</code>, or an <code>Emitter</code>),
it must also consume the messages from within the application (using a method with only <code>@Incoming</code> or using an unmanaged stream).</p>
</div>
</div>
<div class="sect2">
<h3 id="broadcasting-messages-on-multiple-consumers"><a class="anchor" href="#broadcasting-messages-on-multiple-consumers"></a>5.7. Broadcasting messages on multiple consumers</h3>
<div class="paragraph">
<p>By default, a channel can be linked to a single consumer, using <code>@Incoming</code> method or <code>@Channel</code> reactive stream.
At application startup, channels are verified to form a chain of consumers and producers with single consumer and producer.
You can override this behavior by setting <code>mp.messaging.$channel.broadcast=true</code> on a channel.</p>
</div>
<div class="paragraph">
<p>In case of in-memory channels, <code>@Broadcast</code> annotation can be used on the <code>@Outgoing</code> method. For example,</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import java.util.Random;

import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import io.smallrye.reactive.messaging.annotations.Broadcast;

@ApplicationScoped
public class MultipleConsumer {

    private final Random random = new Random();

    @Outgoing("in-memory-channel")
    @Broadcast
    double generate() {
        return random.nextDouble();
    }

    @Incoming("in-memory-channel")
    void consumeAndLog(double price) {
        System.out.println(price);
    }

    @Incoming("in-memory-channel")
    @Outgoing("prices2")
    double consumeAndSend(double price) {
        return price;
    }
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Reciprocally, multiple producers on the same channel can be merged by setting <code>mp.messaging.incoming.$channel.merge=true</code>.
On the <code>@Incoming</code> methods, you can control how multiple channels are merged using the <code>@Merge</code> annotation.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="kafka-transactions"><a class="anchor" href="#kafka-transactions"></a>5.8. Kafka Transactions</h3>
<div class="paragraph">
<p>Kafka transactions enable atomic writes to multiple Kafka topics and partitions.
The Kafka connector provides <code>KafkaTransactions</code> custom emitter for writing Kafka records inside a transaction.
It can be injected as a regular emitter <code>@Channel</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Channel;

import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.kafka.KafkaRecord;
import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;

@ApplicationScoped
public class KafkaTransactionalProducer {

    @Channel("tx-out-example")
    KafkaTransactions&lt;String&gt; txProducer;

    public Uni&lt;Void&gt; emitInTransaction() {
        return txProducer.withTransaction(emitter -&gt; {
            emitter.send(KafkaRecord.of(1, "a"));
            emitter.send(KafkaRecord.of(2, "b"));
            emitter.send(KafkaRecord.of(3, "c"));
            return Uni.createFrom().voidItem();
        });
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The function given to the <code>withTransaction</code> method receives a <code>TransactionalEmitter</code> for producing records, and returns a <code>Uni</code> that provides the result of the transaction.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If the processing completes successfully, the producer is flushed and the transaction is committed.</p>
</li>
<li>
<p>If the processing throws an exception, returns a failing <code>Uni</code>, or marks the <code>TransactionalEmitter</code> for abort, the transaction is aborted.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Kafka transactional producers require configuring <code>acks=all</code> client property, and a unique id for <code>transactional.id</code>, which implies <code>enable.idempotence=true</code>.
When Quarkus detects the use of <code>KafkaTransactions</code> for an outgoing channel it configures these properties on the channel,
providing a default value of <code>"${quarkus.application.name}-${channelName}"</code> for <code>transactional.id</code> property.</p>
</div>
<div class="paragraph">
<p>Note that for production use the <code>transactional.id</code> must be unique across all application instances.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>While a normal message emitter would support concurrent calls to <code>send</code> methods and consequently queues outgoing messages to be written to Kafka,
a <code>KafkaTransactions</code> emitter only supports one transaction at a time.
A transaction is considered in progress from the call to the <code>withTransaction</code> until the returned <code>Uni</code> results in success or failure.
While a transaction is in progress, subsequent calls to the <code>withTransaction</code>, including nested ones inside the given function, will throw <code>IllegalStateException</code>.</p>
</div>
<div class="paragraph">
<p>Note that in Reactive Messaging, the execution of processing methods, is already serialized, unless <code>@Blocking(ordered = false)</code> is used.
If <code>withTransaction</code> can be called concurrently, for example from a REST endpoint, it is recommended to limit the concurrency of the execution.
This can be done using the <code>@Bulkhead</code> annotation from <a href="https://quarkus.io/guides/smallrye-fault-tolerance"><em>Microprofile Fault Tolerance</em></a>.</p>
</div>
<div class="paragraph">
<p>An example usage can be found in <a href="#chaining-kafka-transactions-with-hibernate-reactive-transactions">Chaining Kafka Transactions with Hibernate Reactive transactions</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="transaction-aware-consumers"><a class="anchor" href="#transaction-aware-consumers"></a>5.8.1. Transaction-aware consumers</h4>
<div class="paragraph">
<p>If you&#8217;d like to consume records only written and committed inside a Kafka transaction you need to configure the <code>isolation.level</code> property on the incoming channel as such:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.prices-in.isolation.level=read_committed</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="processing-messages"><a class="anchor" href="#processing-messages"></a>6. Processing Messages</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Applications streaming data often need to consume some events from a topic, process them and publish the result to a different topic.
A processor method can be simply implemented using both the <code>@Incoming</code> and <code>@Outgoing</code> annotations:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import javax.enterprise.context.ApplicationScoped;

@ApplicationScoped
public class PriceProcessor {

    private static final double CONVERSION_RATE = 0.88;

    @Incoming("price-in")
    @Outgoing("price-out")
    public double process(double price) {
        return price * CONVERSION_RATE;
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The parameter of the <code>process</code> method is the incoming message payload, whereas the return value will be used as the outgoing message payload.
Previously mentioned signatures for parameter and return types are also supported, such as <code>Message&lt;T&gt;</code>, <code>Record&lt;K, V&gt;</code>, etc.</p>
</div>
<div class="paragraph">
<p>You can apply asynchronous stream processing by consuming and returning reactive stream <code>Multi&lt;T&gt;</code> type:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import io.smallrye.mutiny.Multi;

@ApplicationScoped
public class PriceProcessor {

    private static final double CONVERSION_RATE = 0.88;

    @Incoming("price-in")
    @Outgoing("price-out")
    public Multi&lt;Double&gt; process(Multi&lt;Integer&gt; prices) {
        return prices.filter(p -&gt; p &gt; 100).map(p -&gt; p * CONVERSION_RATE);
    }

}</code></pre>
</div>
</div>
<div class="sect2">
<h3 id="propagating-record-key"><a class="anchor" href="#propagating-record-key"></a>6.1. Propagating Record Key</h3>
<div class="paragraph">
<p>When processing messages, you can propagate incoming record key to the outgoing record.</p>
</div>
<div class="paragraph">
<p>Enabled with <code>mp.messaging.outgoing.$channel.propagate-record-key=true</code> configuration,
record key propagation produces the outgoing record with the same <em>key</em> as the incoming record.</p>
</div>
<div class="paragraph">
<p>If the outgoing record already contains a <em>key</em>, it <strong>won&#8217;t be overridden</strong> by the incoming record key.
If the incoming record does have a <em>null</em> key, the <code>mp.messaging.outgoing.$channel.key</code> property is used.</p>
</div>
</div>
<div class="sect2">
<h3 id="exactly-once-processing"><a class="anchor" href="#exactly-once-processing"></a>6.2. Exactly-Once Processing</h3>
<div class="paragraph">
<p>Kafka Transactions allows managing consumer offsets inside a transaction, together with produced messages.
This enables coupling a consumer with a transactional producer in a <em>consume-transform-produce</em> pattern, also known as <strong>exactly-once processing</strong>.</p>
</div>
<div class="paragraph">
<p>The <code>KafkaTransactions</code> custom emitter provides a way to apply exactly-once processing to an incoming Kafka message inside a transaction.</p>
</div>
<div class="paragraph">
<p>The following example includes a batch of Kafka records inside a transaction.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.OnOverflow;

import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.kafka.KafkaRecord;
import io.smallrye.reactive.messaging.kafka.KafkaRecordBatch;
import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;

@ApplicationScoped
public class KafkaExactlyOnceProcessor {

    @Channel("prices-out")
    @OnOverflow(value = OnOverflow.Strategy.BUFFER, bufferSize = 500) <i class="conum" data-value="3"></i><b>(3)</b>
    KafkaTransactions&lt;Integer&gt; txProducer;

    @Incoming("prices-in")
    public Uni&lt;Void&gt; emitInTransaction(KafkaRecordBatch&lt;String, Integer&gt; batch) { <i class="conum" data-value="1"></i><b>(1)</b>
        return txProducer.withTransactionAndAck(batch, emitter -&gt; { <i class="conum" data-value="2"></i><b>(2)</b>
            for (KafkaRecord&lt;String, Integer&gt; record : batch) {
                emitter.send(KafkaRecord.of(record.getKey(), record.getPayload() + 1)); <i class="conum" data-value="3"></i><b>(3)</b>
            }
            return Uni.createFrom().voidItem();
        });
    }

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>It is recommended to use exactly-once processing along with the batch consumption mode.
While it is possible to use it with a single Kafka message, it&#8217;ll have a significant performance impact.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The consumed <code>KafkaRecordBatch</code> message is passed to the <code>KafkaTransactions#withTransactionAndAck</code> in order to handle the offset commits and message acks.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The <code>send</code> method writes records to Kafka inside the transaction, without waiting for send receipt from the broker.
Messages pending to be written to Kafka will be buffered, and flushed before committing the transaction.
It is therefore recommended configuring the <code>@OnOverflow</code> <code>bufferSize</code> in order to fit enough messages, for example the <code>max.poll.records</code>, maximum amount of records returned in a batch.
<div class="ulist">
<ul>
<li>
<p>If the processing completes successfully, <em>before committing the transaction</em>, the topic partition offsets of the given batch message will be committed to the transaction.</p>
</li>
<li>
<p>If the processing needs to abort, <em>after aborting the transaction</em>, the consumer&#8217;s position is reset to the last committed offset, effectively resuming the consumption from that offset. If no consumer offset has been committed to a topic-partition, the consumer&#8217;s position is reset to the beginning of the topic-partition, <em>even if the offset reset policy is `latest`</em>.</p>
</li>
</ul>
</div></td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When using exactly-once processing, consumed message offset commits are handled by the transaction and therefore the application should not commit offsets through other means.
The consumer should have <code>enable.auto.commit=false</code> (the default) and set explicitly <code>commit-strategy=ignore</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.prices-in.commit-strategy=ignore
mp.messaging.incoming.prices-in.failure-strategy=ignore</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="error-handling-for-the-exactly-once-processing"><a class="anchor" href="#error-handling-for-the-exactly-once-processing"></a>6.2.1. Error handling for the exactly-once processing</h4>
<div class="paragraph">
<p>The <code>Uni</code> returned from the <code>KafkaTransactions#withTransaction</code> will yield a failure if the transaction fails and is aborted.
The application can choose to handle the error case, but if a failing <code>Uni</code> is returned from the <code>@Incoming</code> method, the incoming channel will effectively fail and stop the reactive stream.</p>
</div>
<div class="paragraph">
<p>The <code>KafkaTransactions#withTransactionAndAck</code> method acks and nacks the message but will <strong>not</strong> return a failing <code>Uni</code>.
Nacked messages will be handled by the failure strategy of the incoming channel, (see <a href="#error-handling">Error Handling Strategies</a>).
Configuring <code>failure-strategy=ignore</code> simply resets the Kafka consumer to the last committed offsets and resumes the consumption from there.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-bare-clients"><a class="anchor" href="#kafka-bare-clients"></a>7. Accessing Kafka clients directly</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In rare cases, you may need to access the underlying Kafka clients.
<code>KafkaClientService</code> provides thread-safe access to <code>Producer</code> and <code>Consumer</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.enterprise.context.ApplicationScoped;
import javax.enterprise.event.Observes;
import javax.inject.Inject;

import org.apache.kafka.clients.producer.ProducerRecord;

import io.quarkus.runtime.StartupEvent;
import io.smallrye.reactive.messaging.kafka.KafkaClientService;
import io.smallrye.reactive.messaging.kafka.KafkaConsumer;
import io.smallrye.reactive.messaging.kafka.KafkaProducer;

@ApplicationScoped
public class PriceSender {

    @Inject
    KafkaClientService clientService;

    void onStartup(@Observes StartupEvent startupEvent) {
        KafkaProducer&lt;String, Double&gt; producer = clientService.getProducer("generated-price");
        producer.runOnSendingThread(client -&gt; client.send(new ProducerRecord&lt;&gt;("prices", 2.4)))
            .await().indefinitely();
    }
}</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The <code>KafkaClientService</code> is an experimental API and can change in the future.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You can also get the Kafka configuration injected to your application and create Kafka producer, consumer and admin clients directly:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.common.annotation.Identifier;
import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.AdminClientConfig;
import org.apache.kafka.clients.admin.KafkaAdminClient;

import javax.enterprise.context.ApplicationScoped;
import javax.enterprise.inject.Produces;
import javax.inject.Inject;
import java.util.HashMap;
import java.util.Map;

@ApplicationScoped
public class KafkaClients {

    @Inject
    @Identifier("default-kafka-broker")
    Map&lt;String, Object&gt; config;

    @Produces
    AdminClient getAdmin() {
        Map&lt;String, Object&gt; copy = new HashMap&lt;&gt;();
        for (Map.Entry&lt;String, Object&gt; entry : config.entrySet()) {
            if (AdminClientConfig.configNames().contains(entry.getKey())) {
                copy.put(entry.getKey(), entry.getValue());
            }
        }
        return KafkaAdminClient.create(copy);
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>default-kafka-broker</code> configuration map contains all application properties prefixed with <code>kafka.</code> or <code>KAFKA_</code>.
For more configuration options check out <a href="#kafka-configuration-resolution">Kafka Configuration Resolution</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-serialization"><a class="anchor" href="#kafka-serialization"></a>8. JSON serialization</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Quarkus has built-in capabilities to deal with JSON Kafka messages.</p>
</div>
<div class="paragraph">
<p>Imagine we have a <code>Fruit</code> data class as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public class Fruit {

    public String name;
    public int price;

    public Fruit() {
    }

    public Fruit(String name, int price) {
        this.name = name;
        this.price = price;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>And we want to use it to receive messages from Kafka, make some price transformation, and send messages back to Kafka.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.smallrye.reactive.messaging.annotations.Broadcast;
import org.eclipse.microprofile.reactive.messaging.Incoming;
import org.eclipse.microprofile.reactive.messaging.Outgoing;

import javax.enterprise.context.ApplicationScoped;

/**
* A bean consuming data from the "fruit-in" channel and applying some price conversion.
* The result is pushed to the "fruit-out" channel.
*/
@ApplicationScoped
public class FruitProcessor {

    private static final double CONVERSION_RATE = 0.88;

    @Incoming("fruit-in")
    @Outgoing("fruit-out")
    @Broadcast
    public Fruit process(Fruit fruit) {
        fruit.price = fruit.price * CONVERSION_RATE;
        return fruit;
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>To do this, we will need to set up JSON serialization with Jackson or JSON-B.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
With JSON serialization correctly configured, you can also use <code>Publisher&lt;Fruit&gt;</code> and <code>Emitter&lt;Fruit&gt;</code>.
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="jackson-serialization"><a class="anchor" href="#jackson-serialization"></a>8.1. Serializing via Jackson</h3>
<div class="paragraph">
<p>Quarkus has built-in support for JSON serialization and deserialization based on Jackson.
It will also <a href="#serialization-generation">generate</a> the serializer and deserializer for you, so you do not have to configure anything.
When generation is disabled, you can use the provided <code>ObjectMapperSerializer</code> and <code>ObjectMapperDeserializer</code> as explained below.</p>
</div>
<div class="paragraph">
<p>There is an existing <code>ObjectMapperSerializer</code> that can be used to serialize all data objects via Jackson.
You may create an empty subclass if you want to use <a href="#serialization-autodetection">Serializer/deserializer autodetection</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
By default, the <code>ObjectMapperSerializer</code> serializes null as the <code>"null"</code> String, this can be customized by setting the Kafka configuration
property <code>json.serialize.null-as-null=true</code> which will serialize null as <code>null</code>.
This is handy when using a compacted topic, as <code>null</code> is used as a tombstone to know which messages delete during compaction phase.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The corresponding deserializer class needs to be subclassed.
So, let&#8217;s create a <code>FruitDeserializer</code> that extends the <code>ObjectMapperDeserializer</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.acme.fruit.jackson;

import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;

public class FruitDeserializer extends ObjectMapperDeserializer&lt;Fruit&gt; {
    public FruitDeserializer() {
        super(Fruit.class);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Finally, configure your channels to use the Jackson serializer and deserializer.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties"># Configure the Kafka source (we read from it)
mp.messaging.incoming.fruit-in.topic=fruit-in
mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jackson.FruitDeserializer

# Configure the Kafka sink (we write to it)
mp.messaging.outgoing.fruit-out.topic=fruit-out
mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now, your Kafka messages will contain a Jackson serialized representation of your <code>Fruit</code> data object.
In this case, the <code>deserializer</code> configuration is not necessary as the <a href="#serialization-autodetection">Serializer/deserializer autodetection</a> is enabled by default.</p>
</div>
<div class="paragraph">
<p>If you want to deserialize a list of fruits, you need to create a deserializer with a Jackson <code>TypeReference</code> denoted the generic collection used.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.acme.fruit.jackson;

import java.util.List;
import com.fasterxml.jackson.core.type.TypeReference;
import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;

public class ListOfFruitDeserializer extends ObjectMapperDeserializer&lt;List&lt;Fruit&gt;&gt; {
    public ListOfFruitDeserializer() {
        super(new TypeReference&lt;List&lt;Fruit&gt;&gt;() {});
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="jsonb-serialization"><a class="anchor" href="#jsonb-serialization"></a>8.2. Serializing via JSON-B</h3>
<div class="paragraph">
<p>First, you need to include the <code>quarkus-jsonb</code> extension.</p>
</div>
<div class="listingblock primary asciidoc-tabs-target-sync-cli asciidoc-tabs-target-sync-maven">
<div class="title">pom.xml</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.quarkus&lt;/groupId&gt;
    &lt;artifactId&gt;quarkus-jsonb&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-target-sync-gradle">
<div class="title">build.gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-gradle hljs" data-lang="gradle">implementation("io.quarkus:quarkus-jsonb")</code></pre>
</div>
</div>
<div class="paragraph">
<p>There is an existing <code>JsonbSerializer</code> that can be used to serialize all data objects via JSON-B.
You may create an empty subclass if you want to use <a href="#serialization-autodetection">Serializer/deserializer autodetection</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
By default, the <code>JsonbSerializer</code> serializes null as the <code>"null"</code> String, this can be customized by setting the Kafka configuration
property <code>json.serialize.null-as-null=true</code> which will serialize null as <code>null</code>.
This is handy when using a compacted topic, as <code>null</code> is used as a tombstone to know which messages delete during compaction phase.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The corresponding deserializer class needs to be subclassed.
So, let&#8217;s create a <code>FruitDeserializer</code> that extends the generic <code>JsonbDeserializer</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.acme.fruit.jsonb;

import io.quarkus.kafka.client.serialization.JsonbDeserializer;

public class FruitDeserializer extends JsonbDeserializer&lt;Fruit&gt; {
    public FruitDeserializer() {
        super(Fruit.class);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Finally, configure your channels to use the JSON-B serializer and deserializer.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties"># Configure the Kafka source (we read from it)
mp.messaging.incoming.fruit-in.connector=smallrye-kafka
mp.messaging.incoming.fruit-in.topic=fruit-in
mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jsonb.FruitDeserializer

# Configure the Kafka sink (we write to it)
mp.messaging.outgoing.fruit-out.connector=smallrye-kafka
mp.messaging.outgoing.fruit-out.topic=fruit-out
mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now, your Kafka messages will contain a JSON-B serialized representation of your <code>Fruit</code> data object.</p>
</div>
<div class="paragraph">
<p>If you want to deserialize a list of fruits, you need to create a deserializer with a <code>Type</code> denoted the generic collection used.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package com.acme.fruit.jsonb;
import java.lang.reflect.Type;
import java.util.ArrayList;
import java.util.List;
import io.quarkus.kafka.client.serialization.JsonbDeserializer;

public class ListOfFruitDeserializer extends JsonbDeserializer&lt;List&lt;Fruit&gt;&gt; {
    public ListOfFruitDeserializer() {
        super(new ArrayList&lt;MyEntity&gt;() {}.getClass().getGenericSuperclass());
    }
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you don&#8217;t want to create a deserializer for each data object, you can use the generic <code>io.vertx.kafka.client.serialization.JsonObjectDeserializer</code>
that will deserialize to a <code>io.vertx.core.json.JsonObject</code>. The corresponding serializer can also be used: <code>io.vertx.kafka.client.serialization.JsonObjectSerializer</code>.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="avro-serialization"><a class="anchor" href="#avro-serialization"></a>9. Avro Serialization</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This is described in a dedicated guide: <a href="kafka-schema-registry-avro">Using Apache Kafka with Schema Registry and Avro</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="serialization-autodetection"><a class="anchor" href="#serialization-autodetection"></a>10. Serializer/deserializer autodetection</h2>
<div class="sectionbody">
<div class="paragraph">
<p>When using SmallRye Reactive Messaging with Kafka (<code>io.quarkus:quarkus-smallrye-reactive-messaging-kafka</code>), Quarkus can often automatically detect the correct serializer and deserializer class.
This autodetection is based on declarations of <code>@Incoming</code> and <code>@Outgoing</code> methods, as well as injected <code>@Channel</code>s.</p>
</div>
<div class="paragraph">
<p>For example, if you declare</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Outgoing("generated-price")
public Multi&lt;Integer&gt; generate() {
    ...
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>and your configuration indicates that the <code>generated-price</code> channel uses the <code>smallrye-kafka</code> connector, then Quarkus will automatically set the <code>value.serializer</code> to Kafka&#8217;s built-in <code>IntegerSerializer</code>.</p>
</div>
<div class="paragraph">
<p>Similarly, if you declare</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Incoming("my-kafka-records")
public void consume(KafkaRecord&lt;Long, byte[]&gt; record) {
    ...
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>and your configuration indicates that the <code>my-kafka-records</code> channel uses the <code>smallrye-kafka</code> connector, then Quarkus will automatically set the <code>key.deserializer</code> to Kafka&#8217;s built-in <code>LongDeserializer</code>, as well as the <code>value.deserializer</code> to <code>ByteArrayDeserializer</code>.</p>
</div>
<div class="paragraph">
<p>Finally, if you declare</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Inject
@Channel("price-create")
Emitter&lt;Double&gt; priceEmitter;</code></pre>
</div>
</div>
<div class="paragraph">
<p>and your configuration indicates that the <code>price-create</code> channel uses the <code>smallrye-kafka</code> connector, then Quarkus will automatically set the <code>value.serializer</code> to Kafka&#8217;s built-in <code>DoubleSerializer</code>.</p>
</div>
<div class="paragraph">
<p>The full set of types supported by the serializer/deserializer autodetection is:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>short</code> and <code>java.lang.Short</code></p>
</li>
<li>
<p><code>int</code> and <code>java.lang.Integer</code></p>
</li>
<li>
<p><code>long</code> and <code>java.lang.Long</code></p>
</li>
<li>
<p><code>float</code> and <code>java.lang.Float</code></p>
</li>
<li>
<p><code>double</code> and <code>java.lang.Double</code></p>
</li>
<li>
<p><code>byte[]</code></p>
</li>
<li>
<p><code>java.lang.String</code></p>
</li>
<li>
<p><code>java.util.UUID</code></p>
</li>
<li>
<p><code>java.nio.ByteBuffer</code></p>
</li>
<li>
<p><code>org.apache.kafka.common.utils.Bytes</code></p>
</li>
<li>
<p><code>io.vertx.core.buffer.Buffer</code></p>
</li>
<li>
<p><code>io.vertx.core.json.JsonObject</code></p>
</li>
<li>
<p><code>io.vertx.core.json.JsonArray</code></p>
</li>
<li>
<p>classes for which a direct implementation of <code>org.apache.kafka.common.serialization.Serializer&lt;T&gt;</code> / <code>org.apache.kafka.common.serialization.Deserializer&lt;T&gt;</code> is present.</p>
<div class="ulist">
<ul>
<li>
<p>the implementation needs to specify the type argument <code>T</code> as the (de-)serialized type.</p>
</li>
</ul>
</div>
</li>
<li>
<p>classes generated from Avro schemas, as well as Avro <code>GenericRecord</code>, if Confluent or Apicurio Registry <em>serde</em> is present</p>
<div class="ulist">
<ul>
<li>
<p>in case multiple Avro serdes are present, serializer/deserializer must be configured manually for Avro-generated classes, because autodetection is impossible</p>
</li>
<li>
<p>see <a href="kafka-schema-registry-avro">Using Apache Kafka with Schema Registry and Avro</a> for more information about using Confluent or Apicurio Registry libraries</p>
</li>
</ul>
</div>
</li>
<li>
<p>classes for which a subclass of <code>ObjectMapperSerializer</code> / <code>ObjectMapperDeserializer</code> is present, as described in <a href="#jackson-serialization">Serializing via Jackson</a></p>
<div class="ulist">
<ul>
<li>
<p>it is technically not needed to subclass <code>ObjectMapperSerializer</code>, but in such case, autodetection isn&#8217;t possible</p>
</li>
</ul>
</div>
</li>
<li>
<p>classes for which a subclass of <code>JsonbSerializer</code> / <code>JsonbDeserializer</code> is present, as described in <a href="#jsonb-serialization">Serializing via JSON-B</a></p>
<div class="ulist">
<ul>
<li>
<p>it is technically not needed to subclass <code>JsonbSerializer</code>, but in such case, autodetection isn&#8217;t possible</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>If a serializer/deserializer is set by configuration, it won&#8217;t be replaced by the autodetection.</p>
</div>
<div class="paragraph">
<p>In case you have any issues with serializer autodetection, you can switch it off completely by setting <code>quarkus.reactive-messaging.kafka.serializer-autodetection.enabled=false</code>.
If you find you need to do this, please file a bug in the <a href="https://github.com/quarkusio/quarkus/issues">Quarkus issue tracker</a> so we can fix whatever problem you have.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="serialization-generation"><a class="anchor" href="#serialization-generation"></a>11. JSON Serializer/deserializer generation</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Quarkus automatically generates serializers and deserializers for channels where:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>the serializer/deserializer is not configured</p>
</li>
<li>
<p>the auto-detection did not find a matching serializer/deserializer</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>It uses Jackson underneath.</p>
</div>
<div class="paragraph">
<p>This generation can be disabled using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.reactive-messaging.kafka.serializer-generation.enabled=false</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Generation does not support collections such as <code>List&lt;Fruit&gt;</code>.
Refer to <a href="#jackson-serialization">Serializing via Jackson</a> to write your own serializer/deserializer for this case.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="using-schema-registry"><a class="anchor" href="#using-schema-registry"></a>12. Using Schema Registry</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This is described in a dedicated guide: <a href="kafka-schema-registry-avro">Using Apache Kafka with Schema Registry and Avro</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-health-check"><a class="anchor" href="#kafka-health-check"></a>13. Health Checks</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Quarkus provides several health checks for Kafka.
These checks are used in combination with the <code>quarkus-smallrye-health</code> extension.</p>
</div>
<div class="sect2">
<h3 id="kafka-broker-readiness-check"><a class="anchor" href="#kafka-broker-readiness-check"></a>13.1. Kafka Broker Readiness Check</h3>
<div class="paragraph">
<p>When using the <code>quarkus-kafka-client</code> extension, you can enable <em>readiness</em> health check by setting the <code>quarkus.kafka.health.enabled</code> property to <code>true</code> in your <code>application.properties</code>.
This check reports the status of the interaction with a <em>default</em> Kafka broker (configured using <code>kafka.bootstrap.servers</code>).
It requires an <em>admin connection</em> with the Kafka broker, and it is disabled by default.
If enabled, when you access the <code>/q/health/ready</code> endpoint of your application, you will have information about the connection validation status.</p>
</div>
</div>
<div class="sect2">
<h3 id="kafka-reactive-messaging-health-checks"><a class="anchor" href="#kafka-reactive-messaging-health-checks"></a>13.2. Kafka Reactive Messaging Health Checks</h3>
<div class="paragraph">
<p>When using Reactive Messaging and the Kafka connector, each configured channel (incoming or outgoing) provides <em>startup</em>, <em>liveness</em> and <em>readiness</em> checks.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The <em>startup</em> check verifies that the communication with Kafka cluster is established.</p>
</li>
<li>
<p>The <em>liveness</em> check captures any unrecoverable failure happening during the communication with Kafka.</p>
</li>
<li>
<p>The <em>readiness</em> check verifies that the Kafka connector is ready to consume/produce messages to the configured Kafka topics.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For each channel, you can disable the checks using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties"># Disable both liveness and readiness checks with `health-enabled=false`:

# Incoming channel (receiving records form Kafka)
mp.messaging.incoming.your-channel.health-enabled=false
# Outgoing channel (writing records to Kafka)
mp.messaging.outgoing.your-channel.health-enabled=false

# Disable only the readiness check with `health-readiness-enabled=false`:

mp.messaging.incoming.your-channel.health-readiness-enabled=false
mp.messaging.outgoing.your-channel.health-readiness-enabled=false</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
You can configure the <code>bootstrap.servers</code> for each channel using <code>mp.messaging.incoming|outgoing.$channel.bootstrap.servers</code> property.
Default is <code>kafka.bootstrap.servers</code>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Reactive Messaging <em>startup</em> and <em>readiness</em> checks offer two strategies.
The default strategy verifies that an active connection is established with the broker.
This approach is not intrusive as it&#8217;s based on built-in Kafka client metrics.</p>
</div>
<div class="paragraph">
<p>Using the <code>health-topic-verification-enabled=true</code> attribute, <em>startup</em> probe uses an <em>admin client</em> to check for the list of topics.
Whereas the <em>readiness</em> probe for an incoming channel checks that at least one partition is assigned for consumption,
and for an outgoing channel checks that the topic used by the producer exist in the broker.</p>
</div>
<div class="paragraph">
<p>Note that to achieve this, an <em>admin connection</em> is required.
You can adjust the timeout for topic verification calls to the broker using the <code>health-topic-verification-timeout</code> configuration.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-streams"><a class="anchor" href="#kafka-streams"></a>14. Kafka Streams</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This is described in a dedicated guide: <a href="kafka-streams">Using Apache Kafka Streams</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="using-snappy-for-message-compression"><a class="anchor" href="#using-snappy-for-message-compression"></a>15. Using Snappy for message compression</h2>
<div class="sectionbody">
<div class="paragraph">
<p>On <em>outgoing</em> channels, you can enable Snappy compression by setting the <code>compression.type</code> attribute to <code>snappy</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.outgoing.fruit-out.compression.type=snappy</code></pre>
</div>
</div>
<div class="paragraph">
<p>In JVM mode, it will work out of the box.
However, to compile your application to a native executable, you need to:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Uses GraalVM 21.+</p>
</li>
<li>
<p>Add <code>quarkus.kafka.snappy.enabled=true</code> to your <code>application.properties</code></p>
</li>
</ol>
</div>
<div class="paragraph">
<p>In native mode, Snappy is disabled by default as the use of Snappy requires embedding a native library and unpacking it when the application starts.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="authentication-with-oauth"><a class="anchor" href="#authentication-with-oauth"></a>16. Authentication with OAuth</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If your Kafka broker uses OAuth as authentication mechanism, you need to configure the Kafka consumer to enable this authentication process.
First, add the following dependency to your application:</p>
</div>
<div class="listingblock primary asciidoc-tabs-target-sync-cli asciidoc-tabs-target-sync-maven">
<div class="title">pom.xml</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.strimzi&lt;/groupId&gt;
    &lt;artifactId&gt;kafka-oauth-client&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-target-sync-gradle">
<div class="title">build.gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-gradle hljs" data-lang="gradle">implementation("io.strimzi:kafka-oauth-client")</code></pre>
</div>
</div>
<div class="paragraph">
<p>This dependency provides the callback handler required to handle the OAuth workflow.
Then, in the <code>application.properties</code>, add:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.connector.smallrye-kafka.security.protocol=SASL_PLAINTEXT
mp.messaging.connector.smallrye-kafka.sasl.mechanism=OAUTHBEARER
mp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
  oauth.client.id="team-a-client" \
  oauth.client.secret="team-a-client-secret" \
  oauth.token.endpoint.uri="http://keycloak:8080/auth/realms/kafka-authz/protocol/openid-connect/token" ;
mp.messaging.connector.smallrye-kafka.sasl.login.callback.handler.class=io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler

quarkus.ssl.native=true</code></pre>
</div>
</div>
<div class="paragraph">
<p>Update the <code>oauth.client.id</code>, <code>oauth.client.secret</code> and <code>oauth.token.endpoint.uri</code> values.</p>
</div>
<div class="paragraph">
<p>OAuth authentication works for both JVM and native modes. Since SSL in not enabled by default in native mode, <code>quarkus.ssl.native=true</code> must be added to support JaasClientOauthLoginCallbackHandler, which uses SSL. (See the <a href="native-and-ssl">Using SSL with Native Executables</a> guide for more details.)</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="testing-a-kafka-application"><a class="anchor" href="#testing-a-kafka-application"></a>17. Testing a Kafka application</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="testing-without-a-broker"><a class="anchor" href="#testing-without-a-broker"></a>17.1. Testing without a broker</h3>
<div class="paragraph">
<p>It can be useful to test the application without having to start a Kafka broker.
To achieve this, you can <em>switch</em> the channels managed by the Kafka connector to <em>in-memory</em>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
This approach only works for JVM tests. It cannot be used for native tests (because they do not support injection).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Let&#8217;s say we want to test the following processor application:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@ApplicationScoped
public class BeverageProcessor {

    @Incoming("orders")
    @Outgoing("beverages")
    Beverage process(Order order) {
        System.out.println("Order received " + order.getProduct());
        Beverage beverage = new Beverage();
        beverage.setBeverage(order.getProduct());
        beverage.setCustomer(order.getCustomer());
        beverage.setOrderId(order.getOrderId());
        beverage.setPreparationState("RECEIVED");
        return beverage;
    }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>First, add the following test dependency to your application:</p>
</div>
<div class="listingblock primary asciidoc-tabs-target-sync-cli asciidoc-tabs-target-sync-maven">
<div class="title">pom.xml</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.smallrye.reactive&lt;/groupId&gt;
    &lt;artifactId&gt;smallrye-reactive-messaging-in-memory&lt;/artifactId&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="listingblock secondary asciidoc-tabs-target-sync-gradle">
<div class="title">build.gradle</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-gradle hljs" data-lang="gradle">testImplementation("io.smallrye.reactive:smallrye-reactive-messaging-in-memory")</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then, create a Quarkus Test Resource as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public class KafkaTestResourceLifecycleManager implements QuarkusTestResourceLifecycleManager {

    @Override
    public Map&lt;String, String&gt; start() {
        Map&lt;String, String&gt; env = new HashMap&lt;&gt;();
        Map&lt;String, String&gt; props1 = InMemoryConnector.switchIncomingChannelsToInMemory("orders");     <i class="conum" data-value="1"></i><b>(1)</b>
        Map&lt;String, String&gt; props2 = InMemoryConnector.switchOutgoingChannelsToInMemory("beverages");  <i class="conum" data-value="2"></i><b>(2)</b>
        env.putAll(props1);
        env.putAll(props2);
        return env;  <i class="conum" data-value="3"></i><b>(3)</b>
    }

    @Override
    public void stop() {
        InMemoryConnector.clear();  <i class="conum" data-value="4"></i><b>(4)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Switch the incoming channel <code>orders</code> (expecting messages from Kafka) to in-memory.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Switch the outgoing channel <code>beverages</code> (writing messages to Kafka) to in-memory.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Builds and returns a <code>Map</code> containing all the properties required to configure the application to use in-memory channels.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>When the test stops, clear the <code>InMemoryConnector</code> (discard all the received and sent messages)</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Create a Quarkus Test using the test resource created above:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@QuarkusTest
@QuarkusTestResource(KafkaTestResourceLifecycleManager.class)
class BaristaTest {

    @Inject
    InMemoryConnector connector; <i class="conum" data-value="1"></i><b>(1)</b>

    @Test
    void testProcessOrder() {
        InMemorySource&lt;Order&gt; ordersIn = connector.source("orders");     <i class="conum" data-value="2"></i><b>(2)</b>
        InMemorySink&lt;Beverage&gt; beveragesOut = connector.sink("beverages");  <i class="conum" data-value="3"></i><b>(3)</b>

        Order order = new Order();
        order.setProduct("coffee");
        order.setName("Coffee lover");
        order.setOrderId("1234");

        ordersIn.send(order);  <i class="conum" data-value="4"></i><b>(4)</b>

        await().&lt;List&lt;? extends Message&lt;Beverage&gt;&gt;&gt;until(beveragesOut::received, t -&gt; t.size() == 1); <i class="conum" data-value="5"></i><b>(5)</b>

        Beverage queuedBeverage = beveragesOut.received().get(0).getPayload();
        Assertions.assertEquals(Beverage.State.READY, queuedBeverage.getPreparationState());
        Assertions.assertEquals("coffee", queuedBeverage.getBeverage());
        Assertions.assertEquals("Coffee lover", queuedBeverage.getCustomer());
        Assertions.assertEquals("1234", queuedBeverage.getOrderId());
    }

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Inject the in-memory connector in your test class.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Retrieve the incoming channel (<code>orders</code>) - the channel must have been switched to in-memory in the test resource.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Retrieve the outgoing channel (<code>beverages</code>) - the channel must have been switched to in-memory in the test resource.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Use the <code>send</code> method to send a message to the <code>orders</code> channel.
The application will process this message and send a message to <code>beverages</code> channel.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Use the <code>received</code> method on <code>beverages</code> channel to check the messages produced by the application.</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>With in-memory channels we were able to test application code processing messages without starting a Kafka broker.
Note that different in-memory channels are independent, and switching channel connector to in-memory does not simulate message delivery between channels configured to the same Kafka topic.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="testing-using-a-kafka-broker"><a class="anchor" href="#testing-using-a-kafka-broker"></a>17.2. Testing using a Kafka broker</h3>
<div class="paragraph">
<p>If you are using <a href="#kafka-dev-services">Dev Services for Kafka</a>, a Kafka broker will be started and available throughout the tests, unless it is disabled in <code>%test</code> profile.
While it is possible to connect to this broker using Kafka Clients API,
<a href="https://smallrye.io/smallrye-reactive-messaging/latest/kafka/test-companion/">Kafka Companion Library</a> proposes an easier way of interacting with a Kafka broker and, creating consumer, producer and admin actions inside tests.</p>
</div>
<div class="paragraph">
<p>For using <code>KafkaCompanion</code> API in tests, start by adding the following dependency:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">&lt;dependency&gt;
    &lt;groupId&gt;io.quarkus&lt;/groupId&gt;
    &lt;artifactId&gt;quarkus-test-kafka-companion&lt;/artifactId&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>which provides <code>io.quarkus.test.kafka.KafkaCompanionResource</code> - an implementation of <code>io.quarkus.test.common.QuarkusTestResourceLifecycleManager</code>.</p>
</div>
<div class="paragraph">
<p>Then use <code>@QuarkusTestResource</code> to configure the Kafka Companion in tests, for example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import static org.junit.jupiter.api.Assertions.assertEquals;

import java.util.UUID;

import org.apache.kafka.clients.producer.ProducerRecord;
import org.junit.jupiter.api.Test;

import io.quarkus.test.common.QuarkusTestResource;
import io.quarkus.test.junit.QuarkusTest;
import io.quarkus.test.kafka.InjectKafkaCompanion;
import io.quarkus.test.kafka.KafkaCompanionResource;
import io.smallrye.reactive.messaging.kafka.companion.ConsumerTask;
import io.smallrye.reactive.messaging.kafka.companion.KafkaCompanion;

@QuarkusTest
@QuarkusTestResource(KafkaCompanionResource.class)
public class OrderProcessorTest {

    @InjectKafkaCompanion <i class="conum" data-value="1"></i><b>(1)</b>
    KafkaCompanion companion;

    @Test
    void testProcessor() {
        companion.produceStrings().usingGenerator(i -&gt; new ProducerRecord&lt;&gt;("orders", UUID.randomUUID().toString())); <i class="conum" data-value="2"></i><b>(2)</b>

        // Expect that the tested application processes orders from 'orders' topic and write to 'orders-processed' topic

        ConsumerTask&lt;String, String&gt; orders = companion.consumeStrings().fromTopics("orders-processed", 10); <i class="conum" data-value="3"></i><b>(3)</b>
        orders.awaitCompletion(); <i class="conum" data-value="4"></i><b>(4)</b>
        assertEquals(10, orders.count());
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><code>@InjectKafkaCompanion</code> injects the <code>KafkaCompanion</code> instance, configured to access the Kafka broker created for tests.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Use <code>KafkaCompanion</code> to create producer task which writes 10 records to 'orders' topic.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Create consumer task which subscribes to 'orders-processed' topic and consumes 10 records.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Await completion of the consumer task.</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If the Kafka Dev Service is available during tests, <code>KafkaCompanionResource</code> uses the created Kafka broker, otherwise it creates a Kafka broker using <a href="https://github.com/strimzi/test-container">Strimzi Test Container</a>.</p>
</div>
<div class="paragraph">
<p>The configuration of the created Kafka broker can be customized using <code>@ResourceArg</code>, for example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@QuarkusTestResource(value = KafkaCompanionResource.class, initArgs = {
        @ResourceArg(name = "strimzi.kafka.image", value = "quay.io/strimzi/kafka:0.28.0-kafka-3.0.0"), // Image name
        @ResourceArg(name = "kafka.port", value = "9092"), // Fixed port for kafka, by default it will be exposed on a random port
        @ResourceArg(name = "kraft", value = "true"), // Enable Kraft mode
        @ResourceArg(name = "num.partitions", value = "3"), // Other custom broker configurations
})
public class OrderProcessorTest {
    // ...
}</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="custom-test-resource"><a class="anchor" href="#custom-test-resource"></a>17.2.1. Custom test resource</h4>
<div class="paragraph">
<p>Alternatively, you can start a Kafka broker in a test resource.
The following snippet shows a test resource starting a Kafka broker using <a href="https://www.testcontainers.org/modules/kafka/">Testcontainers</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">public class KafkaResource implements QuarkusTestResourceLifecycleManager {

    private final KafkaContainer kafka = new KafkaContainer();

    @Override
    public Map&lt;String, String&gt; start() {
        kafka.start();
        return Collections.singletonMap("kafka.bootstrap.servers", kafka.getBootstrapServers());  <i class="conum" data-value="1"></i><b>(1)</b>
    }

    @Override
    public void stop() {
        kafka.close();
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Configure the Kafka bootstrap location, so the application connects to this broker.</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-dev-services"><a class="anchor" href="#kafka-dev-services"></a>18. Dev Services for Kafka</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If any Kafka-related extension is present (e.g. <code>quarkus-smallrye-reactive-messaging-kafka</code>), Dev Services for Kafka automatically starts a Kafka broker in dev mode and when running tests.
So, you don&#8217;t have to start a broker manually.
The application is configured automatically.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Because starting a Kafka broker can be long, Dev Services for Kafka uses <a href="https://vectorized.io/redpanda">Redpanda</a>, a Kafka compatible broker which starts in ~1 second.
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="enabling-disabling-dev-services-for-kafka"><a class="anchor" href="#enabling-disabling-dev-services-for-kafka"></a>18.1. Enabling / Disabling Dev Services for Kafka</h3>
<div class="paragraph">
<p>Dev Services for Kafka is automatically enabled unless:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>quarkus.kafka.devservices.enabled</code> is set to <code>false</code></p>
</li>
<li>
<p>the <code>kafka.bootstrap.servers</code> is configured</p>
</li>
<li>
<p>all the Reactive Messaging Kafka channels have the <code>bootstrap.servers</code> attribute set</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Dev Services for Kafka relies on Docker to start the broker.
If your environment does not support Docker, you will need to start the broker manually, or connect to an already running broker.
You can configure the broker address using <code>kafka.bootstrap.servers</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="shared-broker"><a class="anchor" href="#shared-broker"></a>18.2. Shared broker</h3>
<div class="paragraph">
<p>Most of the time you need to share the broker between applications.
Dev Services for Kafka implements a <em>service discovery</em> mechanism for your multiple Quarkus applications running in <em>dev</em> mode to share a single broker.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Dev Services for Kafka starts the container with the <code>quarkus-dev-service-kafka</code> label which is used to identify the container.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If you need multiple (shared) brokers, you can configure the <code>quarkus.kafka.devservices.service-name</code> attribute and indicate the broker name.
It looks for a container with the same value, or starts a new one if none can be found.
The default service name is <code>kafka</code>.</p>
</div>
<div class="paragraph">
<p>Sharing is enabled by default in dev mode, but disabled in test mode.
You can disable the sharing with <code>quarkus.kafka.devservices.shared=false</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="setting-the-port"><a class="anchor" href="#setting-the-port"></a>18.3. Setting the port</h3>
<div class="paragraph">
<p>By default, Dev Services for Kafka picks a random port and configures the application.
You can set the port by configuring the <code>quarkus.kafka.devservices.port</code> property.</p>
</div>
<div class="paragraph">
<p>Note that the Kafka advertised address is automatically configured with the chosen port.</p>
</div>
</div>
<div class="sect2">
<h3 id="configuring-the-image"><a class="anchor" href="#configuring-the-image"></a>18.4. Configuring the image</h3>
<div class="paragraph">
<p>Dev Services for Kafka supports <a href="https://redpanda.com">Redpanda</a> and <a href="https://strimzi.io">Strimzi</a> (in <a href="https://github.com/apache/kafka/blob/trunk/config/kraft/README.md">Kraft</a> mode).</p>
</div>
<div class="paragraph">
<p>Redpanda is a Kafka compatible event streaming platform.
Because it provides a faster startup time dev services defaults to <code>vectorized/redpanda</code> images.
You can select any version from <a href="https://hub.docker.com/r/vectorized/redpanda" class="bare">https://hub.docker.com/r/vectorized/redpanda</a>.</p>
</div>
<div class="paragraph">
<p>Strimzi provides container images and Operators for running Apache Kafka on Kubernetes.
While Strimzi is optimized for Kubernetes, the images work perfectly in classic container environments.
Strimzi container images run "genuine" Kafka broker on JVM, which is slower to start.</p>
</div>
<div class="paragraph">
<p>For Strimzi, you can select any image with a Kafka version which has Kraft support (2.8.1 and higher) from <a href="https://quay.io/repository/strimzi-test-container/test-container?tab=tags" class="bare">https://quay.io/repository/strimzi-test-container/test-container?tab=tags</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kafka.devservices.image-name=quay.io/strimzi-test-container/test-container:0.100.0-kafka-3.1.0</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="configuring-kafka-topics"><a class="anchor" href="#configuring-kafka-topics"></a>18.5. Configuring Kafka topics</h3>
<div class="paragraph">
<p>You can configure the Dev Services for Kafka to create topics once the broker is started.
Topics are created with given number of partitions and 1 replica.</p>
</div>
<div class="paragraph">
<p>The following example creates a topic named <code>test</code> with 3 partitions, and a second topic named <code>messages</code> with 2 partitions.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kafka.devservices.topic-partitions.test=3
quarkus.kafka.devservices.topic-partitions.messages=2</code></pre>
</div>
</div>
<div class="paragraph">
<p>If a topic already exists with the given name, the creation is skipped,
without trying to re-partition the existing topic to a different number of partitions.</p>
</div>
<div class="paragraph">
<p>You can configure timeout for Kafka admin client calls used in topic creation using <code>quarkus.kafka.devservices.topic-partitions-timeout</code>, it defaults to 2 seconds.</p>
</div>
</div>
<div class="sect2">
<h3 id="redpanda-transactions"><a class="anchor" href="#redpanda-transactions"></a>18.6. Transactional and Idempotent producers support</h3>
<div class="paragraph">
<p>By default, the Red Panda broker is configured to enable transactions and idempotence features.
You can disable those using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kafka.devservices.redpanda.transaction-enabled=false</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Redpanda transactions does not support exactly-once processing.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kubernetes-service-bindings"><a class="anchor" href="#kubernetes-service-bindings"></a>19. Kubernetes Service Bindings</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Quarkus Kafka extension supports
<a href="deploying-to-kubernetes">Service Binding Specification for Kubernetes</a>.
You can enable this by adding the <code>quarkus-kubernetes-service-binding</code> extension to your application.</p>
</div>
<div class="paragraph">
<p>When running in appropriately configured Kubernetes clusters, Kafka extension will pull its Kafka broker connection configuration from the service binding available inside the cluster, without the need for user configuration.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="execution-model"><a class="anchor" href="#execution-model"></a>20. Execution model</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Reactive Messaging invokes user&#8217;s methods on an I/O thread.
Thus, by default, the methods must not block.
As described in <a href="#blocking-processing">Blocking processing</a>, you need to add the <code>@Blocking</code> annotation on the method if this method will block the caller thread.</p>
</div>
<div class="paragraph">
<p>See the <a href="quarkus-reactive-architecture">Quarkus Reactive Architecture documentation</a> for further details on this topic.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="channel-decorators"><a class="anchor" href="#channel-decorators"></a>21. Channel Decorators</h2>
<div class="sectionbody">
<div class="paragraph">
<p>SmallRye Reactive Messaging supports decorating incoming and outgoing channels for implementing cross-cutting concerns such as monitoring, tracing or message interception. For more information on implementing decorators and message interceptors see the <a href="http://smallrye.io/smallrye-reactive-messaging/3.19.1/concepts/decorators/">SmallRye Reactive Messaging documentation</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="kafka-configuration"><a class="anchor" href="#kafka-configuration"></a>22. Configuration Reference</h2>
<div class="sectionbody">
<div class="paragraph">
<p>More details about the SmallRye Reactive Messaging configuration can be found in the <a href="https://smallrye.io/smallrye-reactive-messaging/latest/kafka/kafka/#using-the-kafka-connector">SmallRye Reactive Messaging - Kafka Connector Documentation</a>.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Each channel can be disabled via configuration using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.[incoming|outgoing].[channel].enabled=false</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The most important attributes are listed in the tables below:</p>
</div>
<div class="sect2">
<h3 id="incoming-channel-configuration-polling-from-kafka"><a class="anchor" href="#incoming-channel-configuration-polling-from-kafka"></a>22.1. Incoming channel configuration (polling from Kafka)</h3>
<div class="paragraph">
<p>The following attributes are configured using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.your-channel-name.attribute=value</code></pre>
</div>
</div>
<div class="paragraph">
<p>Some properties have aliases which can be configured globally:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=...</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can also pass any property supported by the underlying <a href="https://kafka.apache.org/documentation/#consumerconfigs">Kafka consumer</a>.</p>
</div>
<div class="paragraph">
<p>For example, to configure the <code>max.poll.records</code> property, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.[channel].max.poll.records=1000</code></pre>
</div>
</div>
<div class="paragraph">
<p>Some consumer client properties are configured to sensible default values:</p>
</div>
<div class="paragraph">
<p>If not set, <code>reconnect.backoff.max.ms</code> is set to <code>10000</code> to avoid high load on disconnection.</p>
</div>
<div class="paragraph">
<p>If not set, <code>key.deserializer</code> is set to <code>org.apache.kafka.common.serialization.StringDeserializer</code>.</p>
</div>
<div class="paragraph">
<p>The consumer <code>client.id</code> is configured according to the number of clients to create using <code>mp.messaging.incoming.[channel].partitions</code> property.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>If a <code>client.id</code> is provided, it is used as-is or suffixed with client index if <code>partitions</code> property is set.</p>
</li>
<li>
<p>If a <code>client.id</code> is not provided, it is generated as <code>kafka-consumer-[channel][-index]</code>.</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Incoming Attributes of the 'smallrye-kafka' connector</caption>
<colgroup>
<col style="width: 27.7777%;">
<col style="width: 33.3333%;">
<col style="width: 16.6666%;">
<col style="width: 22.2224%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Attribute (<em>alias</em>)</th>
<th class="tableblock halign-left valign-top">Description</th>
<th class="tableblock halign-left valign-top">Mandatory</th>
<th class="tableblock halign-left valign-top">Default</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>bootstrap.servers</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(kafka.bootstrap.servers)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A comma-separated list of host:port to use for establishing the initial connection to the Kafka cluster.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>localhost:9092</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>topic</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The consumed / populated Kafka topic. If neither this property nor the <code>topics</code> properties are set, the channel name is used</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether health reporting is enabled (default) or disabled</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether readiness health reporting is enabled (default) or disabled</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-topic-verification</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>deprecated</em> - Whether the readiness check should verify that topics exist on the broker. Default to false. Enabling it requires an admin connection. Deprecated: Use 'health-topic-verification-enabled' instead.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>deprecated</em> - During the readiness health check, the connector connects to the broker and retrieves the list of topics. This attribute specifies the maximum duration (in ms) for the retrieval. If exceeded, the channel is considered not-ready. Deprecated: Use 'health-topic-verification-timeout' instead.</p>
<p class="tableblock">Type: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-topic-verification-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the startup and readiness check should verify that topics exist on the broker. Default to false. Enabling it requires an admin client connection.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-topic-verification-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">During the startup and readiness health check, the connector connects to the broker and retrieves the list of topics. This attribute specifies the maximum duration (in ms) for the retrieval. If exceeded, the channel is considered not-ready.</p>
<p class="tableblock">Type: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2000</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>tracing-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether tracing is enabled (default) or disabled</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enables (default) or disables the Cloud Event support. If enabled on an <em>incoming</em> channel, the connector analyzes the incoming records and try to create Cloud Event metadata. If enabled on an <em>outgoing</em>, the connector sends the outgoing messages as Cloud Event if the message includes Cloud Event Metadata.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>kafka-configuration</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Identifier of a CDI bean that provides the default Kafka consumer/producer configuration for this channel. The channel configuration can still override any attribute. The bean must have a type of Map&lt;String, Object&gt; and must use the @io.smallrye.common.annotation.Identifier qualifier to set the identifier.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>topics</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A comma-separating list of topics to be consumed. Cannot be used with the <code>topic</code> or <code>pattern</code> properties</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>pattern</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Indicate that the <code>topic</code> property is a regular expression. Must be used with the <code>topic</code> property. Cannot be used with the <code>topics</code> property</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key.deserializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The deserializer classname used to deserialize the record&#8217;s key</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>org.apache.kafka.common.serialization.StringDeserializer</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>value.deserializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The deserializer classname used to deserialize the record&#8217;s value</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>fetch.min.bytes</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The minimum amount of data the server should return for a fetch request. The default setting of 1 byte means that fetch requests are answered as soon as a single byte of data is available or the fetch request times out waiting for data to arrive.</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>group.id</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A unique string that identifies the consumer group the application belongs to.</p>
<p class="tableblock">If not set, defaults to the application name as set by the <code>quarkus.application.name</code> configuration property.</p>
<p class="tableblock">If that is not set either, a unique, generated id is used.</p>
<p class="tableblock">It is recommended to always define a <code>group.id</code>, the automatic generation is only a convenient feature for development.
You can explicitly ask for automatically generated unique id by setting this property to <code>${quarkus.uuid}</code>.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>enable.auto.commit</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If enabled, consumer&#8217;s offset will be periodically committed in the background by the underlying Kafka client, ignoring the actual processing outcome of the records. It is recommended to NOT enable this setting and let Reactive Messaging handles the commit.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>retry</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the connection to the broker is re-attempted in case of failure</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>retry-attempts</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The maximum number of reconnection before failing. -1 means infinite retry</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>retry-max-wait</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The max delay (in seconds) between 2 reconnects</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>30</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>broadcast</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the Kafka records should be dispatched to multiple consumer</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>auto.offset.reset</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">What to do when there is no initial offset in Kafka.Accepted values are earliest, latest and none</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>latest</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>failure-strategy</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Specify the failure strategy to apply when a message produced from a record is acknowledged negatively (nack). Values can be <code>fail</code> (default), <code>ignore</code>, or <code>dead-letter-queue</code></p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>fail</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>commit-strategy</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Specify the commit strategy to apply when a message produced from a record is acknowledged. Values can be <code>latest</code>, <code>ignore</code> or <code>throttled</code>. If <code>enable.auto.commit</code> is true then the default is <code>ignore</code> otherwise it is <code>throttled</code></p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>throttled.unprocessed-record-max-age.ms</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">While using the <code>throttled</code> commit-strategy, specify the max age in milliseconds that an unprocessed message can be before the connector is marked as unhealthy. Setting this attribute to 0 disables this monitoring.</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>60000</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>dead-letter-queue.topic</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When the <code>failure-strategy</code> is set to <code>dead-letter-queue</code> indicates on which topic the record is sent. Defaults is <code>dead-letter-topic-$channel</code></p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>dead-letter-queue.key.serializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When the <code>failure-strategy</code> is set to <code>dead-letter-queue</code> indicates the key serializer to use. If not set the serializer associated to the key deserializer is used</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>dead-letter-queue.value.serializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When the <code>failure-strategy</code> is set to <code>dead-letter-queue</code> indicates the value serializer to use. If not set the serializer associated to the value deserializer is used</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>partitions</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The number of partitions to be consumed concurrently. The connector creates the specified amount of Kafka consumers. It should match the number of partition of the targeted topic</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>requests</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When <code>partitions</code> is greater than 1, this attribute allows configuring how many records are requested by each consumer every time.</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>128</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>consumer-rebalance-listener.name</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The name set in <code>@Identifier</code> of a bean that implements <code>io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener</code>. If set, this rebalance listener is applied to the consumer.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key-deserialization-failure-handler</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The name set in <code>@Identifier</code> of a bean that implements <code>io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler</code>. If set, deserialization failure happening when deserializing keys are delegated to this handler which may retry or provide a fallback value.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>value-deserialization-failure-handler</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The name set in <code>@Identifier</code> of a bean that implements <code>io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler</code>. If set, deserialization failure happening when deserializing values are delegated to this handler which may retry or provide a fallback value.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>fail-on-deserialization-failure</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When no deserialization failure handler is set and a deserialization failure happens, report the failure and mark the application as unhealthy. If set to <code>false</code> and a deserialization failure happens, a <code>null</code> value is forwarded.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>graceful-shutdown</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether a graceful shutdown should be attempted when the application terminates.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>poll-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The polling timeout in milliseconds. When polling records, the poll will wait at most that duration before returning records. Default is 1000ms</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1000</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>pause-if-no-requests</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the polling must be paused when the application does not request items and resume when it does. This allows implementing back-pressure based on the application capacity. Note that polling is not stopped, but will not retrieve any records when paused.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>batch</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the Kafka records are consumed in batch. The channel injection point must consume a compatible type, such as <code>List&lt;Payload&gt;</code> or <code>KafkaRecordBatch&lt;Payload&gt;</code>.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>max-queue-size-factor</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Multiplier factor to determine maximum number of records queued for processing, using <code>max.poll.records</code> * <code>max-queue-size-factor</code>. Defaults to 2. In <code>batch</code> mode <code>max.poll.records</code> is considered <code>1</code>.</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2</code></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="outgoing-channel-configuration-writing-to-kafka"><a class="anchor" href="#outgoing-channel-configuration-writing-to-kafka"></a>22.2. Outgoing channel configuration (writing to Kafka)</h3>
<div class="paragraph">
<p>The following attributes are configured using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.outgoing.your-channel-name.attribute=value</code></pre>
</div>
</div>
<div class="paragraph">
<p>Some properties have aliases which can be configured globally:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=...</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can also pass any property supported by the underlying <a href="https://kafka.apache.org/documentation/#producerconfigs">Kafka producer</a>.</p>
</div>
<div class="paragraph">
<p>For example, to configure the <code>max.block.ms</code> property, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.[channel].max.block.ms=10000</code></pre>
</div>
</div>
<div class="paragraph">
<p>Some producer client properties are configured to sensible default values:</p>
</div>
<div class="paragraph">
<p>If not set, <code>reconnect.backoff.max.ms</code> is set to <code>10000</code> to avoid high load on disconnection.</p>
</div>
<div class="paragraph">
<p>If not set, <code>key.serializer</code> is set to <code>org.apache.kafka.common.serialization.StringSerializer</code>.</p>
</div>
<div class="paragraph">
<p>If not set, producer <code>client.id</code> is generated as <code>kafka-producer-[channel]</code>.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. Outgoing Attributes of the 'smallrye-kafka' connector</caption>
<colgroup>
<col style="width: 27.7777%;">
<col style="width: 33.3333%;">
<col style="width: 16.6666%;">
<col style="width: 22.2224%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Attribute (<em>alias</em>)</th>
<th class="tableblock halign-left valign-top">Description</th>
<th class="tableblock halign-left valign-top">Mandatory</th>
<th class="tableblock halign-left valign-top">Default</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>acks</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the durability of records that are sent. Accepted values are: 0, 1, all</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>bootstrap.servers</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(kafka.bootstrap.servers)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A comma-separated list of host:port to use for establishing the initial connection to the Kafka cluster.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>localhost:9092</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>buffer.memory</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The total bytes of memory the producer can use to buffer records waiting to be sent to the server.</p>
<p class="tableblock">Type: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>33554432</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>close-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The amount of milliseconds waiting for a graceful shutdown of the Kafka producer</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>10000</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Enables (default) or disables the Cloud Event support. If enabled on an <em>incoming</em> channel, the connector analyzes the incoming records and try to create Cloud Event metadata. If enabled on an <em>outgoing</em>, the connector sends the outgoing messages as Cloud Event if the message includes Cloud Event Metadata.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-data-content-type</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-data-content-type)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configure the default <code>datacontenttype</code> attribute of the outgoing Cloud Event. Requires <code>cloud-events</code> to be set to <code>true</code>. This value is used if the message does not configure the <code>datacontenttype</code> attribute itself</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-data-schema</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-data-schema)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configure the default <code>dataschema</code> attribute of the outgoing Cloud Event. Requires <code>cloud-events</code> to be set to <code>true</code>. This value is used if the message does not configure the <code>dataschema</code> attribute itself</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-insert-timestamp</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-timestamp)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the connector should insert automatically the <code>time</code> attribute into the outgoing Cloud Event. Requires <code>cloud-events</code> to be set to <code>true</code>. This value is used if the message does not configure the <code>time</code> attribute itself</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-mode</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The Cloud Event mode (<code>structured</code> or <code>binary</code> (default)). Indicates how are written the cloud events in the outgoing record</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>binary</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-source</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-source)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configure the default <code>source</code> attribute of the outgoing Cloud Event. Requires <code>cloud-events</code> to be set to <code>true</code>. This value is used if the message does not configure the <code>source</code> attribute itself</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-subject</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-subject)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configure the default <code>subject</code> attribute of the outgoing Cloud Event. Requires <code>cloud-events</code> to be set to <code>true</code>. This value is used if the message does not configure the <code>subject</code> attribute itself</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>cloud-events-type</strong></span></p>
<p class="tableblock"><span class="no-hyphens"><em>(cloud-events-default-type)</em></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Configure the default <code>type</code> attribute of the outgoing Cloud Event. Requires <code>cloud-events</code> to be set to <code>true</code>. This value is used if the message does not configure the <code>type</code> attribute itself</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether health reporting is enabled (default) or disabled</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether readiness health reporting is enabled (default) or disabled</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>deprecated</em> - During the readiness health check, the connector connects to the broker and retrieves the list of topics. This attribute specifies the maximum duration (in ms) for the retrieval. If exceeded, the channel is considered not-ready. Deprecated: Use 'health-topic-verification-timeout' instead.</p>
<p class="tableblock">Type: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-readiness-topic-verification</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><em>deprecated</em> - Whether the readiness check should verify that topics exist on the broker. Default to false. Enabling it requires an admin connection. Deprecated: Use 'health-topic-verification-enabled' instead.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-topic-verification-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the startup and readiness check should verify that topics exist on the broker. Default to false. Enabling it requires an admin client connection.</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>health-topic-verification-timeout</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">During the startup and readiness health check, the connector connects to the broker and retrieves the list of topics. This attribute specifies the maximum duration (in ms) for the retrieval. If exceeded, the channel is considered not-ready.</p>
<p class="tableblock">Type: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2000</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>kafka-configuration</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Identifier of a CDI bean that provides the default Kafka consumer/producer configuration for this channel. The channel configuration can still override any attribute. The bean must have a type of Map&lt;String, Object&gt; and must use the @io.smallrye.common.annotation.Identifier qualifier to set the identifier.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A key to used when writing the record</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key-serialization-failure-handler</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The name set in <code>@Identifier</code> of a bean that implements <code>io.smallrye.reactive.messaging.kafka.SerializationFailureHandler</code>. If set, serialization failure happening when serializing keys are delegated to this handler which may provide a fallback value.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>key.serializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The serializer classname used to serialize the record&#8217;s key</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>org.apache.kafka.common.serialization.StringSerializer</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>max-inflight-messages</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The maximum number of messages to be written to Kafka concurrently. It limits the number of messages waiting to be written and acknowledged by the broker. You can set this attribute to <code>0</code> remove the limit</p>
<p class="tableblock">Type: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1024</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>merge</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the connector should allow multiple upstreams</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>partition</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The target partition id. -1 to let the client determine the partition</p>
<p class="tableblock">Type: <em>int</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-1</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>propagate-headers</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A comma-separating list of incoming record headers to be propagated to the outgoing record</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>propagate-record-key</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Propagate incoming record key to the outgoing record</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>retries</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If set to a positive number, the connector will try to resend any record that was not delivered successfully (with a potentially transient error) until the number of retries is reached. If set to 0, retries are disabled. If not set, the connector tries to resend any record that failed to be delivered (because of a potentially transient error) during an amount of time configured by <code>delivery.timeout.ms</code>.</p>
<p class="tableblock">Type: <em>long</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2147483647</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>topic</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The consumed / populated Kafka topic. If neither this property nor the <code>topics</code> properties are set, the channel name is used</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>tracing-enabled</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether tracing is enabled (default) or disabled</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>value-serialization-failure-handler</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The name set in <code>@Identifier</code> of a bean that implements <code>io.smallrye.reactive.messaging.kafka.SerializationFailureHandler</code>. If set, serialization failure happening when serializing values are delegated to this handler which may provide a fallback value.</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>value.serializer</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The serializer classname used to serialize the payload</p>
<p class="tableblock">Type: <em>string</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><span class="no-hyphens"><strong>waitForWriteCompletion</strong></span></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the client waits for Kafka to acknowledge the written record before acknowledging the message</p>
<p class="tableblock">Type: <em>boolean</em></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">false</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="kafka-configuration-resolution"><a class="anchor" href="#kafka-configuration-resolution"></a>22.3. Kafka Configuration Resolution</h3>
<div class="paragraph">
<p>Quarkus exposes all Kafka related application properties, prefixed with <code>kafka.</code> or <code>KAFKA_</code> inside a configuration map with <code>default-kafka-broker</code> name.
This configuration is used to establish the connection with the Kafka broker.</p>
</div>
<div class="paragraph">
<p>In addition to this default configuration, you can configure the name of the <code>Map</code> producer using the <code>kafka-configuration</code> attribute:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.my-channel.connector=smallrye-kafka
mp.messaging.incoming.my-channel.kafka-configuration=my-configuration</code></pre>
</div>
</div>
<div class="paragraph">
<p>In this case, the connector looks for the <code>Map</code> associated with the <code>my-configuration</code> name.
If <code>kafka-configuration</code> is not set, an optional lookup for a <code>Map</code> exposed with the channel name (<code>my-channel</code> in the previous example) is done.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Produces
@ApplicationScoped
@Identifier("my-configuration")
Map&lt;String, Object&gt; outgoing() {
    return Map.ofEntries(
            Map.entry("value.serializer", ObjectMapperSerializer.class.getName())
    );
}</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
If <code>kafka-configuration</code> is set and no <code>Map</code> can be found, the deployment fails.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Attribute values are resolved as follows:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>the attribute is set directly on the channel configuration (<code>mp.messaging.incoming.my-channel.attribute=value</code>),</p>
</li>
<li>
<p>if not set, the connector looks for a <code>Map</code> with the channel name or the configured <code>kafka-configuration</code> (if set) and the value is retrieved from that <code>Map</code></p>
</li>
<li>
<p>If the resolved <code>Map</code> does not contain the value the default <code>Map</code> is used (exposed with the <code>default-kafka-broker</code> name)</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="integrating-with-kafka-common-patterns"><a class="anchor" href="#integrating-with-kafka-common-patterns"></a>23. Integrating with Kafka - Common patterns</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="writing-to-kafka-from-an-http-endpoint"><a class="anchor" href="#writing-to-kafka-from-an-http-endpoint"></a>23.1. Writing to Kafka from an HTTP endpoint</h3>
<div class="paragraph">
<p>To send messages to Kafka from an HTTP endpoint, inject an <code>Emitter</code> (or a <code>MutinyEmitter</code>) in your endpoint:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import java.util.concurrent.CompletionStage;

import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

@Path("/")
public class ResourceSendingToKafka {

    @Channel("kafka") Emitter&lt;String&gt; emitter;          <i class="conum" data-value="1"></i><b>(1)</b>

    @POST
    @Produces(MediaType.TEXT_PLAIN)
    public CompletionStage&lt;Void&gt; send(String payload) { <i class="conum" data-value="2"></i><b>(2)</b>
        return emitter.send(payload);                   <i class="conum" data-value="3"></i><b>(3)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Inject an <code>Emitter&lt;String&gt;</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The HTTP method receives the payload and returns a <code>CompletionStage</code> completed when the message is written to Kafka</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Send the message to Kafka, the <code>send</code> method returns a <code>CompletionStage</code></td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The endpoint sends the passed payload (from a <code>POST</code> HTTP request) to the emitter.
The emitter&#8217;s channel is mapped to a Kafka topic in the <code>application.properties</code> file:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.outgoing.kafka.connector=smallrye-kafka
mp.messaging.outgoing.kafka.topic=my-topic</code></pre>
</div>
</div>
<div class="paragraph">
<p>The endpoint returns a <code>CompletionStage</code> indicating the asynchronous nature of the method.
The <code>emitter.send</code> method returns a <code>CompletionStage&lt;Void&gt;</code> .
The returned future is completed when the message has been written to Kafka.
If the writing fails, the returned <code>CompletionStage</code> is completed exceptionally.</p>
</div>
<div class="paragraph">
<p>If the endpoint does not return a <code>CompletionStage</code>, the HTTP response may be written before the message is sent to Kafka, and so failures won&#8217;t be reported to the user.</p>
</div>
<div class="paragraph">
<p>If you need to send a Kafka record, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import java.util.concurrent.CompletionStage;

import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

import io.smallrye.reactive.messaging.kafka.Record;

@Path("/")
public class ResourceSendingToKafka {

    @Channel("kafka") Emitter&lt;Record&lt;String,String&gt;&gt; emitter;  <i class="conum" data-value="1"></i><b>(1)</b>


    @POST
    @Produces(MediaType.TEXT_PLAIN)
    public CompletionStage&lt;Void&gt; send(String payload) {
        return emitter.send(Record.of("my-key", payload));    <i class="conum" data-value="2"></i><b>(2)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Note the usage of an <code>Emitter&lt;Record&lt;K, V&gt;&gt;</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Create the record using <code>Record.of(k, v)</code></td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="persisting-kafka-messages-with-hibernate-with-panache"><a class="anchor" href="#persisting-kafka-messages-with-hibernate-with-panache"></a>23.2. Persisting Kafka messages with Hibernate with Panache</h3>
<div class="paragraph">
<p>To persist objects received from Kafka into a database, you can use Hibernate with Panache.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you use Hibernate Reactive, look at <a href="#persisting-kafka-messages-with-hibernate-reactive">Persisting Kafka messages with Hibernate Reactive</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Let&#8217;s imagine you receive <code>Fruit</code> objects.
For simplicity purposes, our <code>Fruit</code> class is pretty simple:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.persistence.Entity;

import io.quarkus.hibernate.orm.panache.PanacheEntity;

@Entity
public class Fruit extends PanacheEntity {

    public String name;

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>To consume <code>Fruit</code> instances stored on a Kafka topic, and persist them into a database, you can use the following approach:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.enterprise.context.ApplicationScoped;
import javax.transaction.Transactional;

import org.eclipse.microprofile.reactive.messaging.Incoming;

import io.smallrye.common.annotation.Blocking;

@ApplicationScoped
public class FruitConsumer {

    @Incoming("fruits")                                     <i class="conum" data-value="1"></i><b>(1)</b>
    @Transactional                                          <i class="conum" data-value="2"></i><b>(2)</b>
    public void persistFruits(Fruit fruit) {                <i class="conum" data-value="3"></i><b>(3)</b>
        fruit.persist();                                    <i class="conum" data-value="4"></i><b>(4)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Configuring the incoming channel. This channel reads from Kafka.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>As we are writing in a database, we must be in a transaction. This annotation starts a new transaction and commits it when the method returns.
Quarkus automatically considers the method as <em>blocking</em>. Indeed, writing to a database using classic Hibernate is blocking. So, Quarkus calls the method on a worker thread you can block (and not an I/O thread).</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The method receives each Fruit. Note that you would need a deserializer to reconstruct the Fruit instances from the Kafka records.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Persist the received <code>fruit</code> object.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>As mentioned in &lt;4&gt;, you need a deserializer that can create a <code>Fruit</code> from the record.
This can be done using a Jackson deserializer:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;

public class FruitDeserializer extends ObjectMapperDeserializer&lt;Fruit&gt; {
    public FruitDeserializer() {
        super(Fruit.class);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The associated configuration would be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.fruits.connector=smallrye-kafka
mp.messaging.incoming.fruits.value.deserializer=org.acme.FruitDeserializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>Check <a href="#jackson-serialization">Serializing via Jackson</a> for more detail about the usage of Jackson with Kafka.
You can also use Avro.</p>
</div>
</div>
<div class="sect2">
<h3 id="persisting-kafka-messages-with-hibernate-reactive"><a class="anchor" href="#persisting-kafka-messages-with-hibernate-reactive"></a>23.3. Persisting Kafka messages with Hibernate Reactive</h3>
<div class="paragraph">
<p>To persist objects received from Kafka into a database, you can use Hibernate Reactive with Panache.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s imagine you receive <code>Fruit</code> objects.
For simplicity purposes, our <code>Fruit</code> class is pretty simple:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.persistence.Entity;

import io.quarkus.hibernate.reactive.panache.PanacheEntity;  <i class="conum" data-value="1"></i><b>(1)</b>

@Entity
public class Fruit extends PanacheEntity {

    public String name;

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Make sure to use the reactive variant</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To consume <code>Fruit</code> instances stored on a Kafka topic, and persist them into a database, you can use the following approach:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Incoming;

import io.quarkus.hibernate.reactive.panache.Panache;
import io.smallrye.mutiny.Uni;

@ApplicationScoped
public class FruitStore {

    @Inject
    Mutiny.Session session;                    <i class="conum" data-value="1"></i><b>(1)</b>

    @Incoming("in")
    public Uni&lt;Void&gt; consume(Fruit entity) {
        return session.withTransaction(t -&gt; {  <i class="conum" data-value="2"></i><b>(2)</b>
            return entity.persistAndFlush()    <i class="conum" data-value="3"></i><b>(3)</b>
                    .replaceWithVoid();        <i class="conum" data-value="4"></i><b>(4)</b>
        }).onTermination().call(() -&gt; session.close()); <i class="conum" data-value="5"></i><b>(5)</b>
    }

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Inject the Hibernate Reactive <code>Session</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Requests a new transaction. The transaction completes when the passed action completes.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Persist the entity. It returns a <code>Uni&lt;Fruit&gt;</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Switch back to a <code>Uni&lt;Void&gt;</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Close the session - this is close the connection with the database. The connection can then be recycled.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Unlike with <em>classic</em> Hibernate, you can&#8217;t use <code>@Transactional</code>.
Instead, we use <code>session.withTransaction</code> and persist our entity.
The <code>map</code> is used to return a <code>Uni&lt;Void&gt;</code> and not a <code>Uni&lt;Fruit&gt;</code>.</p>
</div>
<div class="paragraph">
<p>You need a deserializer that can create a <code>Fruit</code> from the record.
This can be done using a Jackson deserializer:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;

public class FruitDeserializer extends ObjectMapperDeserializer&lt;Fruit&gt; {
    public FruitDeserializer() {
        super(Fruit.class);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The associated configuration would be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.fruits.connector=smallrye-kafka
mp.messaging.incoming.fruits.value.deserializer=org.acme.FruitDeserializer</code></pre>
</div>
</div>
<div class="paragraph">
<p>Check <a href="#jackson-serialization">Serializing via Jackson</a> for more detail about the usage of Jackson with Kafka.
You can also use Avro.</p>
</div>
</div>
<div class="sect2">
<h3 id="writing-entities-managed-by-hibernate-to-kafka"><a class="anchor" href="#writing-entities-managed-by-hibernate-to-kafka"></a>23.4. Writing entities managed by Hibernate to Kafka</h3>
<div class="paragraph">
<p>Let&#8217;s imagine the following process:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>You receive an HTTP request with a payload,</p>
</li>
<li>
<p>You create an Hibernate entity instance from this payload,</p>
</li>
<li>
<p>You persist that entity into a database,</p>
</li>
<li>
<p>You send the entity to a Kafka topic</p>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you use Hibernate Reactive, look at <a href="#writing-entities-managed-by-hibernate-reactive-to-kafka">Writing entities managed by Hibernate Reactive to Kafka</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Because we write to a database, we must run this method in a transaction.
Yet, sending the entity to Kafka happens asynchronously.
The operation returns a <code>CompletionStage</code> (or a <code>Uni</code> if you use a <code>MutinyEmitter</code>) reporting when the operation completes.
We must be sure that the transaction is still running until the object is written.
Otherwise, you may access the object outside the transaction, which is not allowed.</p>
</div>
<div class="paragraph">
<p>To implement this process, you need the following approach:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import java.util.concurrent.CompletionStage;

import javax.transaction.Transactional;
import javax.ws.rs.POST;
import javax.ws.rs.Path;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.eclipse.microprofile.reactive.messaging.Emitter;

@Path("/")
public class ResourceSendingToKafka {

    @Channel("kafka") Emitter&lt;Fruit&gt; emitter;

    @POST
    @Path("/fruits")
    @Transactional                                                      <i class="conum" data-value="1"></i><b>(1)</b>
    public CompletionStage&lt;Void&gt; storeAndSendToKafka(Fruit fruit) {     <i class="conum" data-value="2"></i><b>(2)</b>
        fruit.persist();
        return emitter.send(fruit);                                     <i class="conum" data-value="3"></i><b>(3)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>As we are writing to the database, make sure we run inside a transaction</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The method receives the fruit instance to persist. It returns a <code>CompletionStage</code> which is used for the transaction demarcation. The transaction is committed when the return <code>CompletionStage</code> completes. In our case, it&#8217;s when the message is written to Kafka.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Send the managed instance to Kafka. Make sure we wait for the message to complete before closing the transaction.</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="writing-entities-managed-by-hibernate-reactive-to-kafka"><a class="anchor" href="#writing-entities-managed-by-hibernate-reactive-to-kafka"></a>23.5. Writing entities managed by Hibernate Reactive to Kafka</h3>
<div class="paragraph">
<p>To send to Kafka entities managed by Hibernate Reactive, we recommend using:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>RESTEasy Reactive to serve HTTP requests</p>
</li>
<li>
<p>A <code>MutinyEmitter</code> to send message to a channel, so it can be easily integrated with the Mutiny API exposed by Hibernate Reactive or Hibernate Reactive with Panache.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The following example demonstrates how to receive a payload, store it in the database using Hibernate Reactive with Panache, and send the persisted entity to Kafka:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.ws.rs.POST;
import javax.ws.rs.Path;

import org.eclipse.microprofile.reactive.messaging.Channel;

import io.quarkus.hibernate.reactive.panache.Panache;
import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.MutinyEmitter;

@Path("/")
public class ReactiveGreetingResource {

    @Channel("kafka") MutinyEmitter&lt;Fruit&gt; emitter;     <i class="conum" data-value="1"></i><b>(1)</b>

    @POST
    @Path("/fruits")
    public Uni&lt;Void&gt; sendToKafka(Fruit fruit) {         <i class="conum" data-value="2"></i><b>(2)</b>
        return Panache.withTransaction(() -&gt;            <i class="conum" data-value="3"></i><b>(3)</b>
            fruit.&lt;Fruit&gt;persist()
        )
            .chain(f -&gt; emitter.send(f));               <i class="conum" data-value="4"></i><b>(4)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Inject a <code>MutinyEmitter</code> which exposes a Mutiny API. It simplifies the integration with the Mutiny API exposed by Hibernate Reactive with Panache.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The HTTP method receiving the payload returns a <code>Uni&lt;Void&gt;</code>. The HTTP response is written when the operation completes (the entity is persisted and written to Kafka).</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>We need to write the entity into the database in a transaction.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Once the persist operation completes, we send the entity to Kafka. The <code>send</code> method returns a <code>Uni&lt;Void&gt;</code>.</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="streaming-kafka-topics-as-server-sent-events"><a class="anchor" href="#streaming-kafka-topics-as-server-sent-events"></a>23.6. Streaming Kafka topics as server-sent events</h3>
<div class="paragraph">
<p>Streaming a Kafka topic as server-sent events (SSE) is straightforward:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>You inject the channel representing the Kafka topic in your HTTP endpoint</p>
</li>
<li>
<p>You return that channel as a <code>Publisher</code> or a <code>Multi</code> from the HTTP method</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The following code provides an example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Channel("fruits")
Multi&lt;Fruit&gt; fruits;

@GET
@Produces(MediaType.SERVER_SENT_EVENTS)
public Multi&lt;Fruit&gt; stream() {
    return fruits;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Some environment cuts the SSE connection when there is not enough activity.
The workaround consists of sending <em>ping</em> messages (or empty objects) periodically.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Channel("fruits")
Multi&lt;Fruit&gt; fruits;

@Inject
ObjectMapper mapper;

@GET
@Produces(MediaType.SERVER_SENT_EVENTS)
public Multi&lt;String&gt; stream() {
    return Multi.createBy().merging()
            .streams(
                    fruits.map(this::toJson),
                    emitAPeriodicPing()
            );
}

Multi&lt;String&gt; emitAPeriodicPing() {
    return Multi.createFrom().ticks().every(Duration.ofSeconds(10))
            .onItem().transform(x -&gt; "{}");
}

private String toJson(Fruit f) {
    try {
        return mapper.writeValueAsString(f);
    } catch (JsonProcessingException e) {
        throw new RuntimeException(e);
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The workaround is a bit more complex as besides sending the fruits coming from Kafka, we need to send pings periodically.
To achieve this we merge the stream coming from Kafka and a periodic stream emitting <code>{}</code> every 10 seconds.</p>
</div>
</div>
<div class="sect2">
<h3 id="chaining-kafka-transactions-with-hibernate-reactive-transactions"><a class="anchor" href="#chaining-kafka-transactions-with-hibernate-reactive-transactions"></a>23.7. Chaining Kafka Transactions with Hibernate Reactive transactions</h3>
<div class="paragraph">
<p>By chaining a Kafka transaction with a Hibernate Reactive transaction you can send records to a Kafka transaction,
perform database updates and commit the Kafka transaction only if the database transaction is successful.</p>
</div>
<div class="paragraph">
<p>The following example demonstrates:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Receive a payload by serving HTTP requests using RESTEasy Reactive,</p>
</li>
<li>
<p>Limit concurrency of that HTTP endpoint using Smallrye Fault Tolerance,</p>
</li>
<li>
<p>Start a Kafka transaction and send the payload to Kafka record,</p>
</li>
<li>
<p>Store the payload in the database using Hibernate Reactive with Panache,</p>
</li>
<li>
<p>Commit the Kafka transaction only if the entity is persisted successfully.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package org.acme;

import javax.ws.rs.Consumes;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.faulttolerance.Bulkhead;
import org.eclipse.microprofile.reactive.messaging.Channel;
import org.hibernate.reactive.mutiny.Mutiny;

import io.quarkus.hibernate.reactive.panache.Panache;
import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;

@Path("/")
public class FruitProducer {

    @Channel("kafka") KafkaTransactions&lt;Fruit&gt; kafkaTx; <i class="conum" data-value="1"></i><b>(1)</b>

    @POST
    @Path("/fruits")
    @Consumes(MediaType.APPLICATION_JSON)
    @Bulkhead(1) <i class="conum" data-value="2"></i><b>(2)</b>
    public Uni&lt;Void&gt; post(Fruit fruit) { <i class="conum" data-value="3"></i><b>(3)</b>
        return kafkaTx.withTransaction(emitter -&gt; { <i class="conum" data-value="4"></i><b>(4)</b>
            emitter.send(fruit); <i class="conum" data-value="5"></i><b>(5)</b>
            return Panache.withTransaction(() -&gt; { <i class="conum" data-value="6"></i><b>(6)</b>
                return fruit.&lt;Fruit&gt;persist(); <i class="conum" data-value="7"></i><b>(7)</b>
            });
        }).replaceWithVoid();
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Inject a <code>KafkaTransactions</code> which exposes a Mutiny API. It allows the integration with the Mutiny API exposed by Hibernate Reactive with Panache.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Limit the concurrency of the HTTP endpoint to "1", preventing starting multiple transactions at a given time.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The HTTP method receiving the payload returns a <code>Uni&lt;Void&gt;</code>. The HTTP response is written when the operation completes (the entity is persisted and Kafka transaction is committed).</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Begin a Kafka transaction.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Send the payload to Kafka inside the Kafka transaction.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Persist the entity into the database in a Hibernate Reactive transaction.</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>Once the persist operation completes, and there is no errors, the Kafka transaction is committed.
The result is omitted and returned as the HTTP response.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In the previous example the database transaction (inner) will commit followed by the Kafka transaction (outer).
If you wish to commit the Kafka transaction first and the database transaction second, you need to nest them in the reverse order.</p>
</div>
<div class="paragraph">
<p>The next example demonstrates that using the Hibernate Reactive API (without Panache):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import javax.inject.Inject;
import javax.ws.rs.Consumes;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.faulttolerance.Bulkhead;
import org.eclipse.microprofile.reactive.messaging.Channel;
import org.hibernate.reactive.mutiny.Mutiny;

import io.smallrye.mutiny.Uni;
import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;
import io.vertx.mutiny.core.Context;
import io.vertx.mutiny.core.Vertx;

@Path("/")
public class FruitProducer {

    @Channel("kafka") KafkaTransactions&lt;Fruit&gt; kafkaTx;

    @Inject Mutiny.SessionFactory sf; <i class="conum" data-value="1"></i><b>(1)</b>

    @POST
    @Path("/fruits")
    @Consumes(MediaType.APPLICATION_JSON)
    @Bulkhead(1)
    public Uni&lt;Void&gt; post(Fruit fruit) {
        Context context = Vertx.currentContext(); <i class="conum" data-value="2"></i><b>(2)</b>
        return sf.withTransaction(session -&gt; <i class="conum" data-value="3"></i><b>(3)</b>
                kafkaTx.withTransaction(emitter -&gt; <i class="conum" data-value="4"></i><b>(4)</b>
                        session.persist(fruit).invoke(() -&gt; emitter.send(fruit)) <i class="conum" data-value="5"></i><b>(5)</b>
                ).emitOn(context::runOnContext) <i class="conum" data-value="6"></i><b>(6)</b>
        );
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Inject the Hibernate Reactive <code>SessionFactory</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Capture the caller Vert.x context.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Begin a Hibernate Reactive transaction.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Begin a Kafka transaction.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Persist the payload and send the entity to Kafka.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>The Kafka transaction terminates on the Kafka producer sender thread.
We need to switch to the Vert.x context previously captured in order to terminate the Hibernate Reactive transaction on the same context we started it.</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="logging"><a class="anchor" href="#logging"></a>24. Logging</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To reduce the amount of log written by the Kafka client, Quarkus sets the level of the following log categories to <code>WARNING</code>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>org.apache.kafka.clients</code></p>
</li>
<li>
<p><code>org.apache.kafka.common.utils</code></p>
</li>
<li>
<p><code>org.apache.kafka.common.metrics</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can override the configuration by adding the following lines to the <code>application.properties</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.log.category."org.apache.kafka.clients".level=INFO
quarkus.log.category."org.apache.kafka.common.utils".level=INFO
quarkus.log.category."org.apache.kafka.common.metrics".level=INFO</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="connecting-to-managed-kafka-clusters"><a class="anchor" href="#connecting-to-managed-kafka-clusters"></a>25. Connecting to Managed Kafka clusters</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section explains how to connect to notorious Kafka Cloud Services.</p>
</div>
<div class="sect2">
<h3 id="azure-event-hub"><a class="anchor" href="#azure-event-hub"></a>25.1. Azure Event Hub</h3>
<div class="paragraph">
<p><a href="https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-for-kafka-ecosystem-overview">Azure Event Hub</a> provides an endpoint compatible with Apache Kafka.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Azure Event Hubs for Kafka is not available in the <em>basic</em> tier.
You need at least the <em>standard</em> tier to use Kafka.
See <a href="https://azure.microsoft.com/en-us/pricing/details/event-hubs/">Azure Event Hubs Pricing</a> to see the other options.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To connect to Azure Event Hub, using the Kafka protocol with TLS, you need the following configuration:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=my-event-hub.servicebus.windows.net:9093 <i class="conum" data-value="1"></i><b>(1)</b>
kafka.security.protocol=SASL_SSL
kafka.sasl.mechanism=PLAIN
kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \ <i class="conum" data-value="2"></i><b>(2)</b>
    username="$ConnectionString" \ <i class="conum" data-value="3"></i><b>(3)</b>
    password="&lt;YOUR.EVENTHUBS.CONNECTION.STRING&gt;"; <i class="conum" data-value="4"></i><b>(4)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The port is <code>9093</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>You need to use the JAAS <code>PlainLoginModule</code>.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The username is the <code>$ConnectionString</code> string.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>The Event Hub connection string given by Azure.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Replace <code>&lt;YOUR.EVENTHUBS.CONNECTION.STRING&gt;</code> with the connection string for your Event Hubs namespace.
For instructions on getting the connection string, see <a href="https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-get-connection-string">Get an Event Hubs connection string</a>.
The result would be something like:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
    username="$ConnectionString" \
    password="Endpoint=sb://my-event-hub.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=XXXXXXXXXXXXXXXX";</code></pre>
</div>
</div>
<div class="paragraph">
<p>This configuration can be global (as above), or set in the channel configuration:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.incoming.$channel.bootstrap.servers=my-event-hub.servicebus.windows.net:9093
mp.messaging.incoming.$channel.security.protocol=SASL_SSL
mp.messaging.incoming.$channel.sasl.mechanism=PLAIN
mp.messaging.incoming.$channel.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
    username="$ConnectionString" \
    password="Endpoint=sb://my-event-hub.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=...";</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="red-hat-openshift-streams-for-apache-kafka"><a class="anchor" href="#red-hat-openshift-streams-for-apache-kafka"></a>25.2. Red Hat OpenShift Streams for Apache Kafka</h3>
<div class="paragraph">
<p><a href="https://cloud.redhat.com/">Red Hat OpenShift Streams for Apache Kafka</a> provides managed Kafka brokers.
First, follow the instructions from <a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3">Getting started with the <code>rhoas</code> CLI for Red Hat OpenShift Streams for Apache Kafka</a> to create your Kafka broker instance.
Make sure you copied the client id and client secret associated with the <em>ServiceAccount</em> you created.</p>
</div>
<div class="paragraph">
<p>Then, you can configure the Quarkus application to connect to the broker as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=&lt;connection url&gt; <i class="conum" data-value="1"></i><b>(1)</b>
kafka.security.protocol=SASL_SSL
kafka.sasl.mechanism=PLAIN
kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="${KAFKA_USERNAME}" \ <i class="conum" data-value="2"></i><b>(2)</b>
  password="${KAFKA_PASSWORD}"; <i class="conum" data-value="3"></i><b>(3)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The connection string, given on the admin console, such as <code>demo-c&#8212;&#8203;bjsv-ldd-cvavkc-a.bf2.kafka.rhcloud.com:443</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The kafka username (the client id from the service account)</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>the kafka password (the client secret from the service account)</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
In general, these properties are prefixed using <code>%prod</code> to enable them only when running in production mode.
</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
As explained in <a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3">Getting started with the rhoas CLI for Red Hat OpenShift Streams for Apache Kafka</a>, to use Red Hat OpenShift Streams for Apache Kafka, you must create the topic beforehand, create a <em>Service Account</em>, and provide permissions to read and write to your topic from that service account.
The authentication data (client id and secret) relates to the service account, which means you can implement fine-grain permissions and restrict access to the topic.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When using Kubernetes, it is recommended to set the client id and secret in a Kubernetes secret:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: v1
kind: Secret
metadata:
  name: kafka-credentials
stringData:
  KAFKA_USERNAME: "..."
  KAFKA_PASSWORD: "..."</code></pre>
</div>
</div>
<div class="paragraph">
<p>To allow your Quarkus application to use that secret, add the following line to the <code>application.properties</code> file:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">%prod.quarkus.openshift.env.secrets=kafka-credentials</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="red-hat-openshift-service-registry"><a class="anchor" href="#red-hat-openshift-service-registry"></a>25.2.1. Red Hat OpenShift Service Registry</h4>
<div class="paragraph">
<p><a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-service-registry">Red Hat OpenShift Service Registry</a>
provides fully managed service registry for handling Kafka schemas.</p>
</div>
<div class="paragraph">
<p>You can follow the instructions from
<a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/ab1894d1-cae0-4d11-b185-81d62b4aabc7#_60472331-fa00-48ec-a621-bbd039500c7d">Getting started with Red Hat OpenShift Service Registry</a>,
or use the <code>rhoas</code> CLI to create a new service registry instance:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rhoas service-registry create --name my-schema-registry</code></pre>
</div>
</div>
<div class="paragraph">
<p>Make sure to note the <em>Registry URL</em> of the instance created.
For authentication, you can use the same <em>ServiceAccount</em> you created previously.
You need to make sure that it has the necessary permissions to access the service registry.</p>
</div>
<div class="paragraph">
<p>For example, using the <code>rhoas</code> CLI, you can grant the <code>MANAGER</code> role to the service account:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">rhoas service-registry role add --role manager --service-account [SERVICE_ACCOUNT_CLIENT_ID]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then, you can configure the Quarkus application to connect to the schema registry as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">mp.messaging.connector.smallrye-kafka.apicurio.registry.url=${RHOAS_SERVICE_REGISTRY_URL} <i class="conum" data-value="1"></i><b>(1)</b>
mp.messaging.connector.smallrye-kafka.apicurio.auth.service.token.endpoint=${RHOAS_OAUTH_TOKEN_ENDPOINT} <i class="conum" data-value="2"></i><b>(2)</b>
mp.messaging.connector.smallrye-kafka.apicurio.auth.client.id=${RHOAS_CLIENT_ID} <i class="conum" data-value="3"></i><b>(3)</b>
mp.messaging.connector.smallrye-kafka.apicurio.auth.client.secret=${RHOAS_CLIENT_ID} <i class="conum" data-value="4"></i><b>(4)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The service registry URL, given on the admin console, such as <code><a href="https://bu98.serviceregistry.rhcloud.com/t/0e95af2c-6e11-475e-82ee-f13bd782df24/apis/registry/v2" class="bare">https://bu98.serviceregistry.rhcloud.com/t/0e95af2c-6e11-475e-82ee-f13bd782df24/apis/registry/v2</a></code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The OAuth token endpoint URL, such as <code><a href="https://identity.api.openshift.com/auth/realms/rhoas/protocol/openid-connect/token" class="bare">https://identity.api.openshift.com/auth/realms/rhoas/protocol/openid-connect/token</a></code></td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The client id (from the service account)</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>The client secret (from the service account)</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="binding-red-hat-openshift-managed-services-to-quarkus-application-using-the-service-binding-operator"><a class="anchor" href="#binding-red-hat-openshift-managed-services-to-quarkus-application-using-the-service-binding-operator"></a>25.2.2. Binding Red Hat OpenShift managed services to Quarkus application using the Service Binding Operator</h4>
<div class="paragraph">
<p>If your Quarkus application is deployed on a Kubernetes or OpenShift cluster with <a href="https://github.com/redhat-developer/service-binding-operator">Service Binding Operator</a> and <a href="https://github.com/redhat-developer/app-services-operator/tree/main/docs">OpenShift Application Services</a> operators installed,
configurations necessary to access Red Hat OpenShift Streams for Apache Kafka and Service Registry can be injected to the application using <a href="deploying-to-kubernetes#service_binding">Kubernetes Service Binding</a>.</p>
</div>
<div class="paragraph">
<p>In order to set up the Service Binding, you need first to connect OpenShift managed services to your cluster.
For an OpenShift cluster you can follow the instructions from <a href="https://github.com/redhat-developer/app-services-guides/tree/main/docs/registry/service-binding-registry#connecting-a-kafka-and-service-registry-instance-to-your-openshift-cluster">Connecting a Kafka and Service Registry instance to your OpenShift cluster</a>.</p>
</div>
<div class="paragraph">
<p>Once you&#8217;ve connected your cluster with the RHOAS Kafka and Service Registry instances, make sure you&#8217;ve granted necessary permissions to the newly created service account.</p>
</div>
<div class="paragraph">
<p>Then, using the <a href="deploying-to-kubernetes#service_binding">Kubernetes Service Binding</a> extension,
you can configure the Quarkus application to generate <code>ServiceBinding</code> resources for those services:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">quarkus.kubernetes-service-binding.detect-binding-resources=true

quarkus.kubernetes-service-binding.services.kafka.api-version=rhoas.redhat.com/v1alpha1
quarkus.kubernetes-service-binding.services.kafka.kind=KafkaConnection
quarkus.kubernetes-service-binding.services.kafka.name=my-kafka

quarkus.kubernetes-service-binding.services.serviceregistry.api-version=rhoas.redhat.com/v1alpha1
quarkus.kubernetes-service-binding.services.serviceregistry.kind=ServiceRegistryConnection
quarkus.kubernetes-service-binding.services.serviceregistry.name=my-schema-registry</code></pre>
</div>
</div>
<div class="paragraph">
<p>For this example Quarkus build will generate the following <code>ServiceBinding</code> resources:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
  name: my-app-kafka
spec:
  application:
    group: apps.openshift.io
    name: my-app
    version: v1
    kind: DeploymentConfig
  services:
    - group: rhoas.redhat.com
      version: v1alpha1
      kind: KafkaConnection
      name: my-kafka
  detectBindingResources: true
  bindAsFiles: true
---
apiVersion: binding.operators.coreos.com/v1alpha1
kind: ServiceBinding
metadata:
  name: my-app-serviceregistry
spec:
  application:
    group: apps.openshift.io
    name: my-app
    version: v1
    kind: DeploymentConfig
  services:
    - group: rhoas.redhat.com
      version: v1alpha1
      kind: ServiceRegistryConnection
      name: my-schema-registry
  detectBindingResources: true
  bindAsFiles: true</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can follow <a href="deploying-to-kubernetes#openshift">Deploying to OpenShift</a> to deploy your application, including generated <code>ServiceBinding</code> resources.
The configuration properties necessary to access the Kafka and Schema Registry instances will be injected to the application automatically at deployment.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="going-further"><a class="anchor" href="#going-further"></a>26. Going further</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This guide has shown how you can interact with Kafka using Quarkus.
It utilizes SmallRye Reactive Messaging to build data streaming applications.</p>
</div>
<div class="paragraph">
<p>If you want to go further, check the documentation of <a href="https://smallrye.io/smallrye-reactive-messaging">SmallRye Reactive Messaging</a>, the implementation used in Quarkus.</p>
</div>
</div>
</div>
    </div>
    <div class="grid__item width-4-12 width-12-12-m tocwrapper">
      <div class="hide-mobile toc"><ul class="sectlevel1">
<li><a href="#introduction">1. Introduction</a></li>
<li><a href="#quarkus-extension-for-apache-kafka">2. Quarkus Extension for Apache Kafka</a></li>
<li><a href="#configuring-smallrye-kafka-connector">3. Configuring Smallrye Kafka Connector</a></li>
<li><a href="#receiving-messages-from-kafka">4. Receiving messages from Kafka</a>
<ul class="sectlevel2">
<li><a href="#blocking-processing">4.1. Blocking processing</a></li>
<li><a href="#acknowledgment-strategies">4.2. Acknowledgment Strategies</a></li>
<li><a href="#commit-strategies">4.3. Commit Strategies</a></li>
<li><a href="#error-handling">4.4. Error Handling Strategies</a></li>
<li><a href="#consumer-groups">4.5. Consumer Groups</a></li>
<li><a href="#receiving-kafka-records-in-batches">4.6. Receiving Kafka Records in Batches</a></li>
</ul>
</li>
<li><a href="#sending-messages-to-kafka">5. Sending messages to Kafka</a>
<ul class="sectlevel2">
<li><a href="#sending-messages-with-emitter">5.1. Sending messages with @Emitter</a></li>
<li><a href="#write-acknowledgement">5.2. Write Acknowledgement</a></li>
<li><a href="#backpressure">5.3. Backpressure</a></li>
<li><a href="#retrying-message-dispatch">5.4. Retrying message dispatch</a></li>
<li><a href="#handling-serialization-failures">5.5. Handling Serialization Failures</a></li>
<li><a href="#in-memory-channels">5.6. In-memory channels</a></li>
<li><a href="#broadcasting-messages-on-multiple-consumers">5.7. Broadcasting messages on multiple consumers</a></li>
<li><a href="#kafka-transactions">5.8. Kafka Transactions</a></li>
</ul>
</li>
<li><a href="#processing-messages">6. Processing Messages</a>
<ul class="sectlevel2">
<li><a href="#propagating-record-key">6.1. Propagating Record Key</a></li>
<li><a href="#exactly-once-processing">6.2. Exactly-Once Processing</a></li>
</ul>
</li>
<li><a href="#kafka-bare-clients">7. Accessing Kafka clients directly</a></li>
<li><a href="#kafka-serialization">8. JSON serialization</a>
<ul class="sectlevel2">
<li><a href="#jackson-serialization">8.1. Serializing via Jackson</a></li>
<li><a href="#jsonb-serialization">8.2. Serializing via JSON-B</a></li>
</ul>
</li>
<li><a href="#avro-serialization">9. Avro Serialization</a></li>
<li><a href="#serialization-autodetection">10. Serializer/deserializer autodetection</a></li>
<li><a href="#serialization-generation">11. JSON Serializer/deserializer generation</a></li>
<li><a href="#using-schema-registry">12. Using Schema Registry</a></li>
<li><a href="#kafka-health-check">13. Health Checks</a>
<ul class="sectlevel2">
<li><a href="#kafka-broker-readiness-check">13.1. Kafka Broker Readiness Check</a></li>
<li><a href="#kafka-reactive-messaging-health-checks">13.2. Kafka Reactive Messaging Health Checks</a></li>
</ul>
</li>
<li><a href="#kafka-streams">14. Kafka Streams</a></li>
<li><a href="#using-snappy-for-message-compression">15. Using Snappy for message compression</a></li>
<li><a href="#authentication-with-oauth">16. Authentication with OAuth</a></li>
<li><a href="#testing-a-kafka-application">17. Testing a Kafka application</a>
<ul class="sectlevel2">
<li><a href="#testing-without-a-broker">17.1. Testing without a broker</a></li>
<li><a href="#testing-using-a-kafka-broker">17.2. Testing using a Kafka broker</a></li>
</ul>
</li>
<li><a href="#kafka-dev-services">18. Dev Services for Kafka</a>
<ul class="sectlevel2">
<li><a href="#enabling-disabling-dev-services-for-kafka">18.1. Enabling / Disabling Dev Services for Kafka</a></li>
<li><a href="#shared-broker">18.2. Shared broker</a></li>
<li><a href="#setting-the-port">18.3. Setting the port</a></li>
<li><a href="#configuring-the-image">18.4. Configuring the image</a></li>
<li><a href="#configuring-kafka-topics">18.5. Configuring Kafka topics</a></li>
<li><a href="#redpanda-transactions">18.6. Transactional and Idempotent producers support</a></li>
</ul>
</li>
<li><a href="#kubernetes-service-bindings">19. Kubernetes Service Bindings</a></li>
<li><a href="#execution-model">20. Execution model</a></li>
<li><a href="#channel-decorators">21. Channel Decorators</a></li>
<li><a href="#kafka-configuration">22. Configuration Reference</a>
<ul class="sectlevel2">
<li><a href="#incoming-channel-configuration-polling-from-kafka">22.1. Incoming channel configuration (polling from Kafka)</a></li>
<li><a href="#outgoing-channel-configuration-writing-to-kafka">22.2. Outgoing channel configuration (writing to Kafka)</a></li>
<li><a href="#kafka-configuration-resolution">22.3. Kafka Configuration Resolution</a></li>
</ul>
</li>
<li><a href="#integrating-with-kafka-common-patterns">23. Integrating with Kafka - Common patterns</a>
<ul class="sectlevel2">
<li><a href="#writing-to-kafka-from-an-http-endpoint">23.1. Writing to Kafka from an HTTP endpoint</a></li>
<li><a href="#persisting-kafka-messages-with-hibernate-with-panache">23.2. Persisting Kafka messages with Hibernate with Panache</a></li>
<li><a href="#persisting-kafka-messages-with-hibernate-reactive">23.3. Persisting Kafka messages with Hibernate Reactive</a></li>
<li><a href="#writing-entities-managed-by-hibernate-to-kafka">23.4. Writing entities managed by Hibernate to Kafka</a></li>
<li><a href="#writing-entities-managed-by-hibernate-reactive-to-kafka">23.5. Writing entities managed by Hibernate Reactive to Kafka</a></li>
<li><a href="#streaming-kafka-topics-as-server-sent-events">23.6. Streaming Kafka topics as server-sent events</a></li>
<li><a href="#chaining-kafka-transactions-with-hibernate-reactive-transactions">23.7. Chaining Kafka Transactions with Hibernate Reactive transactions</a></li>
</ul>
</li>
<li><a href="#logging">24. Logging</a></li>
<li><a href="#connecting-to-managed-kafka-clusters">25. Connecting to Managed Kafka clusters</a>
<ul class="sectlevel2">
<li><a href="#azure-event-hub">25.1. Azure Event Hub</a></li>
<li><a href="#red-hat-openshift-streams-for-apache-kafka">25.2. Red Hat OpenShift Streams for Apache Kafka</a></li>
</ul>
</li>
<li><a href="#going-further">26. Going further</a></li>
</ul></div>
    </div>
  </div>
  </div>

  </div>

  <div class="content project-footer">
  <div class="footer-section">
    <div class="logo-wrapper">
      <a href="/"><img src="/assets/images/quarkus_logo_horizontal_rgb_reverse.svg" class="project-logo" title="Quarkus"></a>
    </div>
  </div>
  <div class="grid-wrapper">
    <p class="grid__item width-3-12">Quarkus is open. All dependencies of this project are available under the <a href='https://www.apache.org/licenses/LICENSE-2.0' target='_blank'>Apache Software License 2.0</a> or compatible license.<br /><br />This website was built with <a href='https://jekyllrb.com/' target='_blank'>Jekyll</a>, is hosted on <a href='https://pages.github.com/' target='_blank'>GitHub Pages</a> and is completely open source. If you want to make it better, <a href='https://github.com/quarkusio/quarkusio.github.io' target='_blank'>fork the website</a> and show us what you’ve got.</p>

    
      <div class="width-1-12 project-links">
        <span>Navigation</span>
        <ul class="footer-links">
          
          
            <li><a href="/" target="_blank">Home</a></li>
          
          
          
            <li><a href="/about" target="_blank">About</a></li>
          
          
          
            <li><a href="/blog" target="_blank">Blog</a></li>
          
          
          
            <li><a href="/insights" target="_blank">Podcast</a></li>
          
          
          
            <li><a href="/events" target="_blank">Events</a></li>
          
          
          
            <li><a href="/newsletter" target="_blank">Newsletter</a></li>
          
          
          
            <li><a href="https://github.com/orgs/quarkusio/projects/13/views/1" target="_blank">Roadmap</a></li>
          
          
          
            <li><a href="/security" target="_blank">Security&nbsp;policy</a></li>
          
          
          
            <li><a href="/usage" target="_blank">Usage</a></li>
          
          
          
            <li><a href="/brand" target="_blank">Brand</a></li>
          
          
          
            <li><a href="/desktopwallpapers" target="_blank">Wallpapers</a></li>
          
          
        </ul>
      </div>
    
      <div class="width-1-12 project-links">
        <span>Follow Us</span>
        <ul class="footer-links">
          
          
            <li><a href="https://x.com/quarkusio" target="_blank">X</a></li>
          
          
          
            <li><a rel="me" href="https://fosstodon.org/@quarkusio" target="_blank">Mastodon</a></li>
            
          
          
            <li><a href="https://www.facebook.com/quarkusio" target="_blank">Facebook</a></li>
          
          
          
            <li><a href="https://www.linkedin.com/company/quarkusio/" target="_blank">Linkedin</a></li>
          
          
          
            <li><a href="https://www.youtube.com/channel/UCaW8QG_QoIk_FnjLgr5eOqg" target="_blank">Youtube</a></li>
          
          
          
            <li><a href="https://github.com/quarkusio" target="_blank">GitHub</a></li>
          
          
        </ul>
      </div>
    
      <div class="width-2-12 project-links">
        <span>Get Help</span>
        <ul class="footer-links">
          
          
            <li><a href="/support" target="_blank">Support</a></li>
          
          
          
            <li><a href="/guides" target="_blank">Guides</a></li>
          
          
          
            <li><a href="/faq" target="_blank">FAQ</a></li>
          
          
          
            <li><a href="/get-started" target="_blank">Get Started</a></li>
          
          
          
            <li><a href="https://stackoverflow.com/questions/tagged/quarkus" target="_blank">Stack Overflow</a></li>
          
          
          
            <li><a href="https://github.com/quarkusio/quarkus/discussions" target="_blank">Discussions</a></li>
          
          
          
            <li><a href="https://groups.google.com/forum/#!forum/quarkus-dev" target="_blank">Development mailing list</a></li>
          
          
        </ul>
      </div>
    
      <div class="width-1-12 project-links">
        <span>Languages</span>
        <ul class="footer-links">
          
          
            <li><a href="https://quarkus.io/" target="_blank">English</a></li>
          
          
          
            <li><a href="https://pt.quarkus.io/" target="_blank">Português&nbsp;(Brasileiro)</a></li>
          
          
          
            <li><a href="https://es.quarkus.io/" target="_blank">Español</a></li>
          
          
          
            <li><a href="https://cn.quarkus.io/" target="_blank">简体中文</a></li>
          
          
          
            <li><a href="https://ja.quarkus.io/" target="_blank">日本語</a></li>
          
          
        </ul>
      </div>
    

    
      <div class="width-4-12 more-links">
        <span>Quarkus is made of community projects</span>
        <ul class="footer-links">
          
            <li><a blah href="https://vertx.io/" target="_blank">Eclipse Vert.x</a></li>
          
            <li><a blah href="https://smallrye.io" target="_blank">SmallRye</a></li>
          
            <li><a blah href="https://hibernate.org" target="_blank">Hibernate</a></li>
          
            <li><a blah href="https://netty.io" target="_blank">Netty</a></li>
          
            <li><a blah href="https://resteasy.github.io" target="_blank">RESTEasy</a></li>
          
            <li><a blah href="https://camel.apache.org" target="_blank">Apache Camel</a></li>
          
            <li><a blah href="https://microprofile.io" target="_blank">Eclipse MicroProfile</a></li>
          
            <li><a blah href="https://code.quarkus.io/" target="_blank">And many more...</a></li>
          
        </ul>
      </div>
    
  </div>
</div>

  <div class="content redhat-footer">
  <div class="grid-wrapper">
    <span class="licence">
      <i class="fab fa-creative-commons"></i><i class="fab fa-creative-commons-by"></i> <a href="https://creativecommons.org/licenses/by/3.0/" target="_blank">CC by 3.0</a> | <a href="https://www.redhat.com/en/about/privacy-policy">Privacy Policy</a>
    </span>
    <span class="redhat">
      Sponsored by
    </span>
    <span class="redhat-logo">
      <a href="https://www.redhat.com/" target="_blank"><img src="/assets/images/redhat_reversed.svg"></a>
    </span>
  </div>
</div>


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>
  <script type="text/javascript" src="/assets/javascript/mobile-nav.js"></script>
  <script type="text/javascript" src="/assets/javascript/scroll-down.js"></script>
  <script src="/assets/javascript/satellite.js" type="text/javascript"></script>
  <script src="/guides/javascript/config.js" type="text/javascript"></script>
  <script src="/assets/javascript/guides-version-dropdown.js" type="text/javascript"></script>
  <script src="/assets/javascript/back-to-top.js" type="text/javascript"></script>
  <script src="/assets/javascript/clipboard.min.js" type="text/javascript"></script>
  <script src="/assets/javascript/copy.js" type="text/javascript"></script>
  <script src="/assets/javascript/asciidoc-tabs.js" type="text/javascript"></script>
  <script src="/assets/javascript/future-date.js" type="text/javascript"></script>
</body>

</html>
